{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34315f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-01T12:30:41.398575Z",
     "iopub.status.busy": "2022-12-01T12:30:41.398129Z",
     "iopub.status.idle": "2022-12-01T12:30:44.246222Z",
     "shell.execute_reply": "2022-12-01T12:30:44.244881Z",
     "shell.execute_reply.started": "2022-12-01T12:30:41.398485Z"
    },
    "papermill": {
     "duration": 0.022153,
     "end_time": "2022-12-02T07:02:47.870469",
     "exception": false,
     "start_time": "2022-12-02T07:02:47.848316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "    # Load packages and fucntion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "92db1a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:02:47.909264Z",
     "iopub.status.busy": "2022-12-02T07:02:47.908603Z",
     "iopub.status.idle": "2022-12-02T07:02:50.149212Z",
     "shell.execute_reply": "2022-12-02T07:02:50.148260Z"
    },
    "papermill": {
     "duration": 2.267421,
     "end_time": "2022-12-02T07:02:50.151970",
     "exception": false,
     "start_time": "2022-12-02T07:02:47.884549",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.256948Z",
     "start_time": "2024-10-09T12:42:22.245839Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.nn import DataParallel\n",
    "\n",
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "from yaml import full_load"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330526ac",
   "metadata": {
    "papermill": {
     "duration": 0.007883,
     "end_time": "2022-12-02T07:02:50.168276",
     "exception": false,
     "start_time": "2022-12-02T07:02:50.160393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 复制粘贴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2dc031",
   "metadata": {
    "papermill": {
     "duration": 0.007751,
     "end_time": "2022-12-02T07:02:50.183912",
     "exception": false,
     "start_time": "2022-12-02T07:02:50.176161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## data_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c44077a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:03:26.435853Z",
     "iopub.status.busy": "2022-12-02T07:03:26.435521Z",
     "iopub.status.idle": "2022-12-02T07:03:26.955353Z",
     "shell.execute_reply": "2022-12-02T07:03:26.954288Z"
    },
    "papermill": {
     "duration": 0.534438,
     "end_time": "2022-12-02T07:03:26.958005",
     "exception": false,
     "start_time": "2022-12-02T07:03:26.423567",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.350973Z",
     "start_time": "2024-10-09T12:42:22.306016Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import scipy\n",
    "import json\n",
    "import copy\n",
    "import base64\n",
    "import zlib\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFile  \n",
    "\n",
    "import sys\n",
    "# sys.path.insert(0, '/home/dongx12/Data/cocoapi/PythonAPI/')\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools.cocoeval import COCOeval\n",
    "from pycocotools import mask as maskUtils\n",
    "\n",
    "# global parameter\n",
    "set_ratio = 0.5\n",
    "\n",
    "def load_json(fileName):\n",
    "    with open(fileName,'r') as data_file:\n",
    "        anno = json.load(data_file)\n",
    "    return anno\n",
    "\n",
    "def mask_to_bbox(mask):\n",
    "    site = np.where(mask>0)\n",
    "    bbox = [np.min(site[1]), np.min(site[0]), np.max(site[1]), np.max(site[0])]\n",
    "    return bbox\n",
    "\n",
    "# ===================== generate edge for input image =====================\n",
    "def show_edge(mask_ori):\n",
    "    mask = mask_ori.copy()\n",
    "    # find countours: img must be binary\n",
    "    myImg = np.zeros((mask.shape[0], mask.shape[1]), np.uint8)\n",
    "    ret, binary = cv2.threshold(np.uint8(mask)*255, 127, 255, cv2.THRESH_BINARY)\n",
    "    countours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE) # RETR_EXTERNAL\n",
    "    '''\n",
    "    cv2.drawContours(myImg, countours, -1, 1, 10)\n",
    "    diff = mask + myImg\n",
    "    diff[diff < 2] = 0\n",
    "    diff[diff == 2] = 1\n",
    "    return diff   \n",
    "    '''\n",
    "    cv2.drawContours(myImg, countours, -1, 1, 4)\n",
    "    return myImg\n",
    "\n",
    "# ===================== load mask =====================\n",
    "def annToRLE(anno, height, width):\n",
    "    \"\"\"\n",
    "    Convert annotation which can be polygons, uncompressed RLE to RLE.\n",
    "    :return: binary mask (numpy 2D array)\n",
    "    \"\"\"\n",
    "    segm = anno['segmentation']\n",
    "    if isinstance(segm, list):\n",
    "        # polygon -- a single object might consist of multiple parts\n",
    "        # we merge all parts into one mask rle code\n",
    "        rles = maskUtils.frPyObjects(segm, height, width)\n",
    "        rle = maskUtils.merge(rles)\n",
    "    elif isinstance(segm['counts'], list):\n",
    "        # uncompressed RLE\n",
    "        rle = maskUtils.frPyObjects(segm, height, width)\n",
    "    else:\n",
    "        # rle\n",
    "        rle = anno['segmentation']\n",
    "    return rle\n",
    "\n",
    "def annToMask(anno, height, width):\n",
    "    \"\"\"\n",
    "    Convert annotation which can be polygons, uncompressed RLE, or RLE to binary mask.\n",
    "    :return: binary mask (numpy 2D array)\n",
    "    \"\"\"\n",
    "    rle = annToRLE(anno, height, width)\n",
    "    mask = maskUtils.decode(rle)\n",
    "    return mask\n",
    "\n",
    "def base64_2_mask(s):\n",
    "    z = zlib.decompress(base64.b64decode(s))\n",
    "    n = np.fromstring(z, np.uint8)\n",
    "    mask = cv2.imdecode(n, cv2.IMREAD_UNCHANGED)[:, :, 3].astype(bool)\n",
    "    return mask\n",
    "\n",
    "def mask_2_base64(mask):\n",
    "    img_pil = Image.fromarray(np.array(mask, dtype=np.uint8))\n",
    "    img_pil.putpalette([0,0,0,255,255,255])\n",
    "    bytes_io = io.BytesIO()\n",
    "    img_pil.save(bytes_io, format='PNG', transparency=0, optimize=0)\n",
    "    bytes = bytes_io.getvalue()\n",
    "    return base64.b64encode(zlib.compress(bytes)).decode('utf-8')\n",
    "\n",
    "# ===================== deformable data augmentation for input image =====================\n",
    "def flip_data(width, keypoint_ori):\n",
    "    keypoint = copy.deepcopy(keypoint_ori)\n",
    "    for i in xrange(len(keypoint)/3):\n",
    "        keypoint[3*i] = width - 1 - keypoint[3*i]\n",
    "    right = [2,4, 6,8,10, 12,14,16]\n",
    "    left  = [1,3, 5,7,9,  11,13,15]\n",
    "    \n",
    "    for i in xrange(len(left)):\n",
    "        temp = copy.deepcopy(keypoint[3*right[i]:3*(right[i]+1)]) \n",
    "        keypoint[3*right[i]:3*(right[i]+1)] = keypoint[3*left[i]:3*(left[i]+1)]\n",
    "        keypoint[3*left[i]:3*(left[i]+1)] = temp\n",
    "    return keypoint\n",
    "\n",
    "def data_aug_flip(image, mask):\n",
    "    if random.random()<set_ratio:\n",
    "        return image, mask, False\n",
    "    return image[:,::-1,:], mask[:,::-1], True\n",
    "\n",
    "def aug_matrix(img_w, img_h, bbox, w, h, angle_range=(-45, 45), scale_range=(0.5, 1.5), offset=40):\n",
    "    ''' \n",
    "    first Translation, then rotate, final scale.\n",
    "        [sx, 0, 0]       [cos(theta), -sin(theta), 0]       [1, 0, dx]       [x]\n",
    "        [0, sy, 0] (dot) [sin(theta),  cos(theta), 0] (dot) [0, 1, dy] (dot) [y]\n",
    "        [0,  0, 1]       [         0,           0, 1]       [0, 0,  1]       [1]\n",
    "    '''\n",
    "    ratio = 1.0*(bbox[2]-bbox[0])*(bbox[3]-bbox[1])/(img_w*img_h)\n",
    "    x_offset = (random.random()-0.5) * 2 * offset\n",
    "    y_offset = (random.random()-0.5) * 2 * offset\n",
    "    dx = (w-(bbox[2]+bbox[0]))/2.0 \n",
    "    dy = (h-(bbox[3]+bbox[1]))/2.0\n",
    "    \n",
    "    matrix_trans = np.array([[1.0, 0, dx],\n",
    "                             [0, 1.0, dy],\n",
    "                             [0, 0,   1.0]])\n",
    "\n",
    "    angle = random.random()*(angle_range[1]-angle_range[0])+angle_range[0]\n",
    "    scale = random.random()*(scale_range[1]-scale_range[0])+scale_range[0]\n",
    "    scale *= np.mean([float(w)/(bbox[2]-bbox[0]), float(h)/(bbox[3]-bbox[1])])\n",
    "    alpha = scale * math.cos(angle/180.0*math.pi)\n",
    "    beta = scale * math.sin(angle/180.0*math.pi)\n",
    "\n",
    "    centerx = w/2.0 + x_offset\n",
    "    centery = h/2.0 + y_offset\n",
    "    H = np.array([[alpha, beta, (1-alpha)*centerx-beta*centery], \n",
    "                  [-beta, alpha, beta*centerx+(1-alpha)*centery],\n",
    "                  [0,         0,                            1.0]])\n",
    "\n",
    "    H = H.dot(matrix_trans)[0:2, :]\n",
    "    return H  \n",
    "\n",
    "# ===================== texture data augmentation for input image =====================\n",
    "def data_aug_light(image):\n",
    "    if random.random()<set_ratio:\n",
    "        return image\n",
    "    value = random.randint(-30, 30)\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_image = np.array(hsv_image, dtype=np.float32)\n",
    "    hsv_image[:,:,2] += value\n",
    "    hsv_image[hsv_image>255] = 255\n",
    "    hsv_image[hsv_image<0] = 0\n",
    "    hsv_image = np.array(hsv_image, dtype=np.uint8)\n",
    "    image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "    return image    \n",
    "\n",
    "def data_aug_blur(image):\n",
    "    if random.random()<set_ratio:\n",
    "        return image\n",
    "    \n",
    "    select = random.random()\n",
    "    if select < 0.3:\n",
    "        kernalsize = random.choice([3,5])\n",
    "        image = cv2.GaussianBlur(image, (kernalsize,kernalsize),0)\n",
    "    elif select < 0.6:\n",
    "        kernalsize = random.choice([3,5])\n",
    "        image = cv2.medianBlur(image, kernalsize)\n",
    "    else:\n",
    "        kernalsize = random.choice([3,5])\n",
    "        image = cv2.blur(image, (kernalsize,kernalsize))\n",
    "    return image\n",
    "\n",
    "def data_aug_color(image):  \n",
    "    if random.random()<set_ratio:\n",
    "        return image\n",
    "    random_factor = np.random.randint(4, 17) / 10. \n",
    "    color_image = ImageEnhance.Color(image).enhance(random_factor) \n",
    "    random_factor = np.random.randint(4, 17) / 10. \n",
    "    brightness_image = ImageEnhance.Brightness(color_image).enhance(random_factor)\n",
    "    random_factor = np.random.randint(6, 15) / 10. \n",
    "    contrast_image = ImageEnhance.Contrast(brightness_image).enhance(random_factor)\n",
    "    random_factor = np.random.randint(8, 13) / 10.\n",
    "    return ImageEnhance.Sharpness(contrast_image).enhance(random_factor)\n",
    "\n",
    "def data_aug_noise(image):\n",
    "    if random.random()<set_ratio:\n",
    "        return image\n",
    "    mu = 0\n",
    "    sigma = random.random()*10.0\n",
    "    image = np.array(image, dtype=np.float32)\n",
    "    image += np.random.normal(mu, sigma, image.shape)\n",
    "    image[image>255] = 255\n",
    "    image[image<0] = 0\n",
    "    return image\n",
    "\n",
    "# ===================== normalization for input image =====================\n",
    "def padding(img_ori, mask_ori, size=224, padding_color=128):\n",
    "    height = img_ori.shape[0]\n",
    "    width = img_ori.shape[1]\n",
    "    \n",
    "    img = np.zeros((max(height, width), max(height, width), 3)) + padding_color\n",
    "    mask = np.zeros((max(height, width), max(height, width)))\n",
    "    \n",
    "    if (height > width):\n",
    "        padding = int((height-width)/2)\n",
    "        img[:, padding:padding+width, :] = img_ori\n",
    "        mask[:, padding:padding+width] = mask_ori\n",
    "    else:\n",
    "        padding = int((width-height)/2)\n",
    "        img[padding:padding+height, :, :] = img_ori\n",
    "        mask[padding:padding+height, :] = mask_ori\n",
    "        \n",
    "    img = np.uint8(img)\n",
    "    mask = np.uint8(mask)\n",
    "    \n",
    "    img = cv2.resize(img, (size, size), interpolation=cv2.INTER_CUBIC)\n",
    "    mask = cv2.resize(mask, (size, size), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    return np.array(img, dtype=np.float32),  np.array(mask, dtype=np.float32)\n",
    "\n",
    "def Normalize_Img(imgOri, scale, mean, val):\n",
    "    img = np.array(imgOri.copy(), np.float32)/scale\n",
    "    if len(img.shape) == 4:\n",
    "        for j in range(img.shape[0]):\n",
    "            for i in range(len(mean)):\n",
    "                img[j,:,:,i] = (img[j,:,:,i]-mean[i])*val[i]\n",
    "        return img\n",
    "    else:\n",
    "        for i in range(len(mean)):\n",
    "            img[:,:,i] = (img[:,:,i]-mean[i])*val[i]\n",
    "        return img\n",
    "\n",
    "def Anti_Normalize_Img(imgOri, scale, mean, val):\n",
    "    img = np.array(imgOri.copy(), np.float32)\n",
    "    if len(img.shape) == 4:\n",
    "        for j in range(img.shape[0]):\n",
    "            for i in range(len(mean)):\n",
    "                img[j,:,:,i] = img[j,:,:,i]/val[i]+mean[i]\n",
    "        return np.array(img*scale, np.uint8)\n",
    "    else:\n",
    "        for i in range(len(mean)):\n",
    "            img[:,:,i] = img[:,:,i]/val[i]+mean[i]\n",
    "        return np.array(img*scale, np.uint8)\n",
    "    \n",
    "# ===================== generate prior channel for input image =====================\n",
    "def data_motion_blur(image, mask):\n",
    "    if random.random()<set_ratio:\n",
    "        return image, mask\n",
    "    \n",
    "    degree = random.randint(5, 30)\n",
    "    angle = random.randint(0, 360)\n",
    "    \n",
    "    M = cv2.getRotationMatrix2D((degree/2, degree/2), angle, 1)\n",
    "    motion_blur_kernel = np.diag(np.ones(degree))\n",
    "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
    "    motion_blur_kernel = motion_blur_kernel/degree\n",
    "    \n",
    "    img_blurred = cv2.filter2D(image, -1, motion_blur_kernel)\n",
    "    mask_blurred = cv2.filter2D(mask, -1, motion_blur_kernel)\n",
    "    \n",
    "    cv2.normalize(img_blurred, img_blurred, 0, 255, cv2.NORM_MINMAX)\n",
    "    cv2.normalize(mask_blurred, mask_blurred, 0, 1, cv2.NORM_MINMAX)\n",
    "    return img_blurred, mask_blurred\n",
    "    \n",
    "def data_motion_blur_prior(prior):\n",
    "    if random.random()<set_ratio:\n",
    "        return prior\n",
    "    \n",
    "    degree = random.randint(5, 30)\n",
    "    angle = random.randint(0, 360)\n",
    "    \n",
    "    M = cv2.getRotationMatrix2D((degree/2, degree/2), angle, 1)\n",
    "    motion_blur_kernel = np.diag(np.ones(degree))\n",
    "    motion_blur_kernel = cv2.warpAffine(motion_blur_kernel, M, (degree, degree))\n",
    "    motion_blur_kernel = motion_blur_kernel/degree\n",
    "    \n",
    "    prior_blurred = cv2.filter2D(prior, -1, motion_blur_kernel)\n",
    "    return prior_blurred  \n",
    "    \n",
    "def data_Affine(image, mask, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return image, mask\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 12)\n",
    "    pts1 = np.float32([[0+bias[0], 0+bias[1]], [width+bias[2], 0+bias[3]], [0+bias[4], height+bias[5]]])\n",
    "    pts2 = np.float32([[0+bias[6], 0+bias[7]], [width+bias[8], 0+bias[9]], [0+bias[10], height+bias[11]]])\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    img_affine = cv2.warpAffine(image, M, (width, height))\n",
    "    mask_affine = cv2.warpAffine(mask, M, (width, height))\n",
    "    return img_affine, mask_affine\n",
    "\n",
    "def data_Affine_prior(prior, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return prior\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 12)\n",
    "    pts1 = np.float32([[0+bias[0], 0+bias[1]], [width+bias[2], 0+bias[3]], [0+bias[4], height+bias[5]]])\n",
    "    pts2 = np.float32([[0+bias[6], 0+bias[7]], [width+bias[8], 0+bias[9]], [0+bias[10], height+bias[11]]])\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "    prior_affine = cv2.warpAffine(prior, M, (width, height))\n",
    "    return prior_affine\n",
    "    \n",
    "def data_Perspective(image, mask, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return image, mask\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 16)\n",
    "    pts1 = np.float32([[0+bias[0],0+bias[1]], [height+bias[2],0+bias[3]], \n",
    "                       [0+bias[4],width+bias[5]], [height+bias[6], width+bias[7]]])\n",
    "    pts2 = np.float32([[0+bias[8],0+bias[9]], [height+bias[10],0+bias[11]], \n",
    "                       [0+bias[12],width+bias[13]], [height+bias[14], width+bias[15]]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    img_perspective = cv2.warpPerspective(image, M, (width, height))\n",
    "    mask_perspective = cv2.warpPerspective(mask, M, (width, height))\n",
    "    return img_perspective, mask_perspective\n",
    "\n",
    "def data_Perspective_prior(prior, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return prior\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 16)\n",
    "    pts1 = np.float32([[0+bias[0],0+bias[1]], [height+bias[2],0+bias[3]], \n",
    "                       [0+bias[4],width+bias[5]], [height+bias[6], width+bias[7]]])\n",
    "    pts2 = np.float32([[0+bias[8],0+bias[9]], [height+bias[10],0+bias[11]], \n",
    "                       [0+bias[12],width+bias[13]], [height+bias[14], width+bias[15]]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    prior_perspective = cv2.warpPerspective(prior, M, (width, height))\n",
    "    return prior_perspective\n",
    "\n",
    "def data_ThinPlateSpline(image, mask, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return image, mask\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 16)\n",
    "    tps = cv2.createThinPlateSplineShapeTransformer()\n",
    "    sshape = np.array([[0+bias[0],0+bias[1]], [height+bias[2],0+bias[3]], \n",
    "                       [0+bias[4],width+bias[5]], [height+bias[6], width+bias[7]]], np.float32)\n",
    "    tshape = np.array([[0+bias[8],0+bias[9]], [height+bias[10],0+bias[11]], \n",
    "                       [0+bias[12],width+bias[13]], [height+bias[14], width+bias[15]]], np.float32)\n",
    "    sshape = sshape.reshape(1,-1,2)\n",
    "    tshape = tshape.reshape(1,-1,2)\n",
    "    matches = list()\n",
    "    matches.append(cv2.DMatch(0,0,0))\n",
    "    matches.append(cv2.DMatch(1,1,0))\n",
    "    matches.append(cv2.DMatch(2,2,0))\n",
    "    matches.append(cv2.DMatch(3,3,0))\n",
    "    \n",
    "    tps.estimateTransformation(tshape, sshape, matches)\n",
    "    res = tps.warpImage(image)\n",
    "    res_mask = tps.warpImage(mask)\n",
    "    return res, res_mask   \n",
    "\n",
    "def data_ThinPlateSpline_prior(prior, height, width, ratio=0.05):\n",
    "    if random.random()<set_ratio:\n",
    "        return prior\n",
    "    bias = np.random.randint(-int(height*ratio),int(width*ratio), 16)\n",
    "    tps = cv2.createThinPlateSplineShapeTransformer()\n",
    "    sshape = np.array([[0+bias[0],0+bias[1]], [height+bias[2],0+bias[3]], \n",
    "                       [0+bias[4],width+bias[5]], [height+bias[6], width+bias[7]]], np.float32)\n",
    "    tshape = np.array([[0+bias[8],0+bias[9]], [height+bias[10],0+bias[11]], \n",
    "                       [0+bias[12],width+bias[13]], [height+bias[14], width+bias[15]]], np.float32)\n",
    "    sshape = sshape.reshape(1,-1,2)\n",
    "    tshape = tshape.reshape(1,-1,2)\n",
    "    matches = list()\n",
    "    matches.append(cv2.DMatch(0,0,0))\n",
    "    matches.append(cv2.DMatch(1,1,0))\n",
    "    matches.append(cv2.DMatch(2,2,0))\n",
    "    matches.append(cv2.DMatch(3,3,0))\n",
    "    \n",
    "    tps.estimateTransformation(tshape, sshape, matches)\n",
    "    prior = tps.warpImage(prior)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdce1ec",
   "metadata": {
    "papermill": {
     "duration": 0.009657,
     "end_time": "2022-12-02T07:03:26.977532",
     "exception": false,
     "start_time": "2022-12-02T07:03:26.967875",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## datasets_portraitseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "456715a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:03:26.998675Z",
     "iopub.status.busy": "2022-12-02T07:03:26.998317Z",
     "iopub.status.idle": "2022-12-02T07:03:27.047910Z",
     "shell.execute_reply": "2022-12-02T07:03:27.046880Z"
    },
    "papermill": {
     "duration": 0.063161,
     "end_time": "2022-12-02T07:03:27.050191",
     "exception": false,
     "start_time": "2022-12-02T07:03:26.987030",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.382555Z",
     "start_time": "2024-10-09T12:42:22.352475Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import scipy\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from easydict import EasyDict as edict\n",
    "\n",
    "import json\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image\n",
    "# from PIL import ImageFile\n",
    "# ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "# from data_aug import data_aug_blur, data_aug_color, data_aug_noise, data_aug_light\n",
    "# from data_aug import data_aug_flip, flip_data, aug_matrix\n",
    "# from data_aug import show_edge, mask_to_bbox, load_json\n",
    "# from data_aug import base64_2_mask, mask_2_base64, padding, Normalize_Img, Anti_Normalize_Img\n",
    "# from data_aug import data_motion_blur, data_Affine, data_Perspective, data_ThinPlateSpline\n",
    "# from data_aug import data_motion_blur_prior, data_Affine_prior, data_Perspective_prior, data_ThinPlateSpline_prior\n",
    "\n",
    "class PortraitSeg(data.Dataset): \n",
    "    def __init__(self, ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, exp_args):\n",
    "        self.ImageRoot = ImageRoot\n",
    "        self.AnnoRoot = AnnoRoot\n",
    "        self.istrain = exp_args.istrain\n",
    "        self.stability = exp_args.stability\n",
    "        self.addEdge = exp_args.addEdge\n",
    "        \n",
    "        self.video = exp_args.video\n",
    "        self.prior_prob = exp_args.prior_prob\n",
    "        \n",
    "        self.task = exp_args.task\n",
    "        self.dataset = exp_args.dataset #eg1800\n",
    "        self.input_height = exp_args.input_height\n",
    "        self.input_width = exp_args.input_width\n",
    "        \n",
    "        self.padding_color = exp_args.padding_color\n",
    "        self.img_scale = exp_args.img_scale\n",
    "        self.img_mean = exp_args.img_mean # BGR order\n",
    "        self.img_val = exp_args.img_val # BGR order\n",
    "        \n",
    "        if self.istrain == True:\n",
    "            file_object = open(ImgIds_Train, 'r')\n",
    "        elif self.istrain == False:\n",
    "            file_object = open(ImgIds_Test, 'r')\n",
    "            \n",
    "        try:\n",
    "            self.imgIds = file_object.readlines() #1447\n",
    "            if self.dataset == \"MscocoBackground\" and self.istrain == True:\n",
    "                self.imgIds = self.imgIds[:5000]\n",
    "                \n",
    "            if self.dataset == \"ATR\" and self.istrain == True:\n",
    "                self.imgIds = self.imgIds[:5000]\n",
    "            \n",
    "            # if self.istrain == False:\n",
    "            #     self.imgIds = self.imgIds[:100]\n",
    "                \n",
    "        finally:\n",
    "             file_object.close()\n",
    "        pass\n",
    "            \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        '''\n",
    "        An item is an image. Which may contains more than one person.\n",
    "        '''\n",
    "        img = None\n",
    "        mask = None\n",
    "        bbox = None\n",
    "        H = None\n",
    "        \n",
    "        if self.dataset == \"supervisely\":\n",
    "            # basic info\n",
    "            img_path = os.path.join(self.ImageRoot, self.imgIds[index].strip())\n",
    "            img_name = img_path[img_path.rfind('/')+1:]\n",
    "            img = cv2.imread(img_path)\n",
    "            \n",
    "            # load mask\n",
    "            annopath = img_path.replace('/img/', '/ann/')\n",
    "            annopath = annopath[:annopath.find('.')]+'.json'\n",
    "            ann = load_json(annopath)\n",
    "            mask = np.zeros((img.shape[0], img.shape[1]), dtype=np.float32)\n",
    "            for i in range(len(ann['objects'])):\n",
    "                mask_temp = np.zeros((img.shape[0], img.shape[1]))\n",
    "                if ann['objects'][i]['classTitle'] == 'person_poly':\n",
    "                    points = np.array(ann['objects'][i]['points']['exterior'])\n",
    "                    if len(points) > 0:\n",
    "                        cv2.fillPoly(mask_temp, [points], 1)\n",
    "                        points = np.array(ann['objects'][i]['points']['interior'])\n",
    "                        for p in points:\n",
    "                            cv2.fillPoly(mask_temp, [np.array(p)], 0)\n",
    "                elif ann['objects'][i]['classTitle'] == 'neutral':\n",
    "                    points = np.array(ann['objects'][i]['points']['exterior'])\n",
    "                    if len(points) > 0:\n",
    "                        cv2.fillPoly(mask_temp, [points], 1)\n",
    "                        points = np.array(ann['objects'][i]['points']['interior'])\n",
    "                        for p in points:\n",
    "                            cv2.fillPoly(mask_temp, [np.array(p)], 0)\n",
    "                elif ann['objects'][i]['classTitle'] == 'person_bmp':\n",
    "                    data = np.array(ann['objects'][i]['bitmap']['data'])\n",
    "                    if data.size > 0:\n",
    "                        mask_ = base64_2_mask(data)\n",
    "                        origin = ann['objects'][i]['bitmap']['origin']\n",
    "                        mask_temp[origin[1]:origin[1]+mask_.shape[0], origin[0]:origin[0]+mask_.shape[1]] = mask_\n",
    "                mask[mask_temp>0] = 1\n",
    "            \n",
    "            height, width, channel = img.shape\n",
    "            # bbox = mask_to_bbox(mask)\n",
    "            bbox = [0, 0, width-1, height-1]\n",
    "            \n",
    "            H = aug_matrix(width, height, bbox, self.input_width, self.input_height,\n",
    "                       angle_range=(-45, 45), scale_range=(0.5, 1.5), offset=self.input_height/4)\n",
    "            \n",
    "        elif self.dataset in [\"supervisely_face_easy\", \"supervisely_face_difficult\"]:\n",
    "            # basic info\n",
    "            img_path = os.path.join(self.ImageRoot, self.imgIds[index].strip())\n",
    "            img_name = img_path[img_path.rfind('/')+1:]\n",
    "            img = cv2.imread(img_path)\n",
    "            # img = cv2.imread(img_path.replace('/img/', '/imgAug/'))\n",
    "            \n",
    "            # load mask\n",
    "            annopath = img_path.replace('/img/', '/ann/')\n",
    "            # annopath = img_path.replace('/img/', '/maskAug/')\n",
    "            \n",
    "            mask = cv2.imread(annopath, 0) # origin mask = 255\n",
    "            mask[mask>0] = 1\n",
    "            \n",
    "            height, width, channel = img.shape\n",
    "            # bbox = mask_to_bbox(mask)\n",
    "            bbox = [0, 0, width-1, height-1]\n",
    "            H = aug_matrix(width, height, bbox, self.input_width, self.input_height,\n",
    "                       angle_range=(-45, 45), scale_range=(0.5, 1.5), offset=self.input_height/4)\n",
    "            \n",
    "        elif self.dataset in [\"flickr\", \"eg1800\", \"liveshow\"]:\n",
    "            # basic info\n",
    "            img_id = self.imgIds[index].strip()\n",
    "            img_path = os.path.join(self.ImageRoot, img_id)\n",
    "            img = cv2.imread(img_path)\n",
    "            # img = cv2.imread(img_path.replace('Images', 'ImagesAug'))\n",
    "            img_name = img_path[img_path.rfind('/')+1:]\n",
    "            \n",
    "            # load mask\n",
    "            annopath = os.path.join(self.AnnoRoot, img_id.replace('.jpg', '.png'))\n",
    "            mask = cv2.imread(annopath, 0)\n",
    "            # mask = cv2.imread(annopath.replace('Labels', 'LabelsAug'), 0)\n",
    "            mask[mask>1] = 0\n",
    "            \n",
    "            height, width, channel = img.shape\n",
    "            bbox = [0, 0, width-1, height-1]\n",
    "            H = aug_matrix(width, height, bbox, self.input_width, self.input_height,\n",
    "                       angle_range=(-45, 45), scale_range=(0.5, 1.5), offset=self.input_height/4)\n",
    "        \n",
    "        elif self.dataset == \"ATR\":\n",
    "            # basic info\n",
    "            img_id = self.imgIds[index].strip()\n",
    "            img_path = os.path.join(self.ImageRoot, img_id)\n",
    "            img = cv2.imread(img_path)\n",
    "            img_name = img_path[img_path.rfind('/')+1:]\n",
    "            \n",
    "            # load mask\n",
    "            annopath = os.path.join(self.AnnoRoot, img_id.replace('.jpg', '.png'))\n",
    "            mask = cv2.imread(annopath, 0) \n",
    "            mask[mask>1] = 1\n",
    "            \n",
    "            height, width, channel = img.shape\n",
    "            bbox = [0, 0, width-1, height-1]\n",
    "            H = aug_matrix(width, height, bbox, self.input_width, self.input_height,\n",
    "                       angle_range=(-45, 45), scale_range=(0.5, 1.5), offset=self.input_height/4)\n",
    "        \n",
    "        elif self.dataset == \"MscocoBackground\":\n",
    "            # basic info\n",
    "            img_path = self.imgIds[index].strip()\n",
    "            img_path = os.path.join(self.ImageRoot, img_path)\n",
    "            img = cv2.imread(img_path)\n",
    "            height, width, channel = img.shape\n",
    "            mask = np.zeros((height, width))\n",
    "            \n",
    "            bbox = [0, 0, width-1, height-1]\n",
    "            H = aug_matrix(width, height, bbox, self.input_width, self.input_height,\n",
    "                       angle_range=(-45, 45), scale_range=(1.5, 2.0), offset=self.input_height/4)\n",
    "            \n",
    "        use_float_mask = False # use original 0/1 mask as groundtruth\n",
    "        \n",
    "        # data augument: first align center to center of dst size. then rotate and scale\n",
    "        if self.istrain == False:\n",
    "            img_aug_ori, mask_aug_ori = padding(img, mask, size=self.input_width, padding_color=self.padding_color)\n",
    "            \n",
    "            # ===========add new channel for video stability============\n",
    "            input_norm = Normalize_Img(img_aug_ori, scale=self.img_scale, mean=self.img_mean, val=self.img_val)\n",
    "            if self.video == True:\n",
    "                prior = np.zeros((self.input_height, self.input_width, 1))\n",
    "                input_norm = np.c_[input_norm, prior]\n",
    "            input = np.transpose(input_norm, (2, 0, 1))\n",
    "            input_ori = copy.deepcopy(input)\n",
    "        else:\n",
    "            img_aug = cv2.warpAffine(np.uint8(img), H, (self.input_width, self.input_height), \n",
    "                                     flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, \n",
    "                                     borderValue=(self.padding_color, self.padding_color, self.padding_color)) \n",
    "            mask_aug = cv2.warpAffine(np.uint8(mask), H, (self.input_width, self.input_height), \n",
    "                                      flags=cv2.INTER_NEAREST, borderMode=cv2.BORDER_CONSTANT)\n",
    "            img_aug_ori, mask_aug_ori, aug_flag = data_aug_flip(img_aug, mask_aug)\n",
    "            prior = np.zeros((self.input_height, self.input_width, 1))\n",
    "            \n",
    "            # ======== add new channel for video stability =========\n",
    "            if self.video == True and self.prior_prob >= random.random(): # add new augmentation\n",
    "                prior[:,:,0] = mask_aug_ori.copy()\n",
    "                prior = np.array(prior, dtype=np.float)\n",
    "                \n",
    "                if random.random() >= 0.5:\n",
    "                    # modify image + mask, use groundtruth as prior\n",
    "                    img_aug_ori = np.array(img_aug_ori)\n",
    "                    mask_aug_ori = np.array(mask_aug_ori, dtype=np.float)\n",
    "                    img_aug_ori, mask_aug_ori = data_motion_blur(img_aug_ori, mask_aug_ori)\n",
    "                    img_aug_ori, mask_aug_ori = data_Affine(img_aug_ori, mask_aug_ori, self.input_height, self.input_width, ratio=0.05)\n",
    "                    img_aug_ori, mask_aug_ori = data_Perspective(img_aug_ori, mask_aug_ori, self.input_height, self.input_width, ratio=0.05)\n",
    "                    img_aug_ori, mask_aug_ori = data_ThinPlateSpline(img_aug_ori, mask_aug_ori, self.input_height, self.input_width, ratio=0.05)\n",
    "                    use_float_mask = True\n",
    "                else:\n",
    "                    # modify prior, don't change image + mask\n",
    "                    prior = data_motion_blur_prior(prior)\n",
    "                    prior = data_Affine_prior(prior, self.input_height, self.input_width, ratio=0.05)\n",
    "                    prior = data_Perspective_prior(prior, self.input_height, self.input_width, ratio=0.05)\n",
    "                    prior = data_ThinPlateSpline_prior(prior, self.input_height, self.input_width, ratio=0.05)\n",
    "                    prior = prior.reshape(self.input_height, self.input_width, 1)\n",
    "                \n",
    "            # add augmentation\n",
    "            img_aug = Image.fromarray(cv2.cvtColor(img_aug_ori, cv2.COLOR_BGR2RGB))  \n",
    "            img_aug = data_aug_color(img_aug)\n",
    "            img_aug = np.asarray(img_aug)\n",
    "            # img_aug = data_aug_light(img_aug)\n",
    "            img_aug = data_aug_blur(img_aug)\n",
    "            img_aug = data_aug_noise(img_aug)\n",
    "            img_aug = np.float32(img_aug[:,:,::-1]) # BGR, like cv2.imread\n",
    "            \n",
    "            input_norm = Normalize_Img(img_aug, scale=self.img_scale, mean=self.img_mean, val=self.img_val)\n",
    "            input_ori_norm = Normalize_Img(img_aug_ori, scale=self.img_scale, mean=self.img_mean, val=self.img_val)\n",
    "                \n",
    "            if self.video == True:\n",
    "                input_norm = np.c_[input_norm, prior]\n",
    "                input_ori_norm = np.c_[input_ori_norm, prior]\n",
    "            \n",
    "            input = np.transpose(input_norm, (2, 0, 1))\n",
    "            input_ori = np.transpose(input_ori_norm, (2, 0, 1))\n",
    "            \n",
    "        if 'seg' in self.task:\n",
    "            if use_float_mask == True:\n",
    "                output_mask = cv2.resize(mask_aug_ori, (self.input_width, self.input_height), interpolation=cv2.INTER_NEAREST)\n",
    "                cv2.normalize(output_mask, output_mask, 0, 1, cv2.NORM_MINMAX)\n",
    "                output_mask[output_mask>=0.5] = 1\n",
    "                output_mask[output_mask<0.5] = 0\n",
    "            else:\n",
    "                output_mask = cv2.resize(np.uint8(mask_aug_ori), (self.input_width, self.input_height), interpolation=cv2.INTER_NEAREST)\n",
    "                \n",
    "                # add mask blur\n",
    "                output_mask = np.uint8(cv2.blur(output_mask, (5,5)))\n",
    "                output_mask[output_mask>=0.5] = 1\n",
    "                output_mask[output_mask<0.5] = 0\n",
    "        else:\n",
    "            output_mask = np.zeros((self.input_height, self.input_width), dtype=np.uint8) + 255\n",
    "        \n",
    "        if self.task == 'seg':\n",
    "            edge = show_edge(output_mask)\n",
    "            # edge_blur = np.uint8(cv2.blur(edge, (5,5)))/255.0\n",
    "            return input_ori, input, edge, output_mask\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.imgIds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fec5b6",
   "metadata": {
    "papermill": {
     "duration": 0.00926,
     "end_time": "2022-12-02T07:03:27.068965",
     "exception": false,
     "start_time": "2022-12-02T07:03:27.059705",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c8fb226",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:03:27.089560Z",
     "iopub.status.busy": "2022-12-02T07:03:27.089233Z",
     "iopub.status.idle": "2022-12-02T07:03:27.106520Z",
     "shell.execute_reply": "2022-12-02T07:03:27.105560Z"
    },
    "papermill": {
     "duration": 0.030321,
     "end_time": "2022-12-02T07:03:27.108826",
     "exception": false,
     "start_time": "2022-12-02T07:03:27.078505",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.398383Z",
     "start_time": "2024-10-09T12:42:22.383848Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "# from datasets_portraitseg import PortraitSeg\n",
    "\n",
    "class Human(data.Dataset): \n",
    "    def __init__(self, exp_args):\n",
    "        assert exp_args.task in ['seg'], 'Error!, <task> should in [seg]'\n",
    "        \n",
    "        self.exp_args = exp_args\n",
    "        self.task = exp_args.task\n",
    "        self.datasetlist = exp_args.datasetlist #['EG1800']\n",
    "        self.data_root = exp_args.data_root # data_root = '/home/dongx12/Data/'\n",
    "        #/home/liuchang/portraitNet/PortraitNet-master/Data/\n",
    "        self.file_root = exp_args.file_root # file_root = '/home/dongx12/PortraitNet/data/select_data/'\n",
    "        #/home/liuchang/portraitNet/PortraitNet-master/data/select_data/\n",
    "        self.datasets = {}\n",
    "        self.imagelist = []\n",
    "        \n",
    "        # load dataset\n",
    "        if 'supervisely' in self.datasetlist:\n",
    "            ImageRoot = self.data_root\n",
    "            AnnoRoot = self.data_root\n",
    "            ImgIds_Train = self.file_root + 'supervisely_train_new.txt'\n",
    "            ImgIds_Test = self.file_root + 'supervisely_test_new.txt'\n",
    "            exp_args.dataset = 'supervisely'\n",
    "            self.datasets['supervisely'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "        \n",
    "        if 'EG1800' in self.datasetlist:\n",
    "            ImageRoot = self.data_root + 'EG1800/Images/'\n",
    "            AnnoRoot = self.data_root + 'EG1800/Labels/'\n",
    "            ImgIds_Train = self.file_root + 'eg1800_train.txt'\n",
    "            ImgIds_Test = self.file_root + 'eg1800_test.txt'\n",
    "            exp_args.dataset = 'eg1800'\n",
    "            self.datasets['eg1800'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "        \n",
    "        if 'ATR' in self.datasetlist:\n",
    "            ImageRoot = self.data_root + 'ATR/train/images/'\n",
    "            AnnoRoot = self.data_root + 'ATR/train/seg/'\n",
    "            ImgIds_Train = self.file_root + 'ATR_train.txt'\n",
    "            ImgIds_Test = self.file_root + 'ATR_test.txt'\n",
    "            exp_args.dataset = 'ATR'\n",
    "            self.datasets['ATR'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "        \n",
    "        if 'supervisely_face_easy' in self.datasetlist:\n",
    "            ImageRoot = self.data_root\n",
    "            AnnoRoot = self.data_root\n",
    "            ImgIds_Train = self.file_root + 'supervisely_face_train_easy.txt'\n",
    "            ImgIds_Test = self.file_root + 'supervisely_face_test_easy.txt'\n",
    "            exp_args.dataset = 'supervisely_face_easy'\n",
    "            self.datasets['supervisely_face_easy'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "            \n",
    "        if 'supervisely_face_difficult' in self.datasetlist:\n",
    "            ImageRoot = self.data_root\n",
    "            AnnoRoot = self.data_root\n",
    "            ImgIds_Train = self.file_root + 'supervisely_face_train_difficult.txt'\n",
    "            ImgIds_Test = self.file_root + 'supervisely_face_test_difficult.txt'\n",
    "            exp_args.dataset = 'supervisely_face_difficult'\n",
    "            self.datasets['supervisely_face_difficult'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "        \n",
    "        if 'MscocoBackground' in self.datasetlist:\n",
    "            dataType = 'train2017'\n",
    "            ImageRoot = self.data_root\n",
    "            AnnoRoot = self.data_root + 'mscoco2017/annotations/person_keypoints_{}.json'.format(dataType)\n",
    "            ImgIds_Train = self.file_root + 'select_mscoco_background_train2017.txt'\n",
    "            ImgIds_Test = self.file_root + 'select_mscoco_background_val2017.txt'\n",
    "            exp_args.dataset = 'MscocoBackground'\n",
    "            self.datasets['background'] = PortraitSeg(ImageRoot, AnnoRoot, ImgIds_Train, ImgIds_Test, self.exp_args)\n",
    "\n",
    "            \n",
    "        # image list\n",
    "        for key in self.datasets.keys():\n",
    "            length = len(self.datasets[key])\n",
    "            for i in range(length): # eg1800 1447\n",
    "                self.imagelist.append([key, i])\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        subset, subsetidx = self.imagelist[index]\n",
    "        \n",
    "        if self.task == 'seg':\n",
    "            input_ori, input, output_edge, output_mask = self.datasets[subset][subsetidx]\n",
    "            return input_ori.astype(np.float32), input.astype(np.float32), \\\n",
    "        output_edge.astype(np.int64), output_mask.astype(np.int64)\n",
    "           \n",
    "    def __len__(self):\n",
    "        return len(self.imagelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdd034",
   "metadata": {
    "papermill": {
     "duration": 0.009589,
     "end_time": "2022-12-02T07:03:27.128172",
     "exception": false,
     "start_time": "2022-12-02T07:03:27.118583",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## focal loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9bbc6c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:03:27.150026Z",
     "iopub.status.busy": "2022-12-02T07:03:27.149088Z",
     "iopub.status.idle": "2022-12-02T07:03:27.160869Z",
     "shell.execute_reply": "2022-12-02T07:03:27.159803Z"
    },
    "papermill": {
     "duration": 0.024874,
     "end_time": "2022-12-02T07:03:27.163066",
     "exception": false,
     "start_time": "2022-12-02T07:03:27.138192",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.414393Z",
     "start_time": "2024-10-09T12:42:22.399379Z"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Code referenced from: \n",
    "https://github.com/clcarwin/focal_loss_pytorch/blob/master/focalloss.py\n",
    "'''\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        if isinstance(alpha,(float,int)): self.alpha = torch.Tensor([alpha,1-alpha])\n",
    "        if isinstance(alpha,list): self.alpha = torch.Tensor(alpha)\n",
    "        self.size_average = size_average\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        if input.dim()>2:\n",
    "            input = input.view(input.size(0),input.size(1),-1) # N,C,H,W => N,C,H*W\n",
    "            input = input.transpose(1,2) # N,C,H*W => N,H*W,C\n",
    "            input = input.contiguous().view(-1,input.size(2)) # N,H*W,C => N*H*W,C\n",
    "        target = target.view(-1,1)\n",
    "\n",
    "        logpt = F.log_softmax(input)\n",
    "        logpt = logpt.gather(1,target)\n",
    "        logpt = logpt.view(-1)\n",
    "        pt = Variable(logpt.data.exp())\n",
    "\n",
    "        if self.alpha is not None:\n",
    "            if self.alpha.type()!=input.data.type():\n",
    "                self.alpha = self.alpha.type_as(input.data)\n",
    "            at = self.alpha.gather(0,target.data.view(-1))\n",
    "            logpt = logpt * Variable(at)\n",
    "\n",
    "        loss = -1 * (1-pt)**self.gamma * logpt\n",
    "        \n",
    "        if self.size_average: \n",
    "            return loss.mean()\n",
    "        else: \n",
    "            return loss.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c87032",
   "metadata": {
    "papermill": {
     "duration": 0.009882,
     "end_time": "2022-12-02T07:03:27.182920",
     "exception": false,
     "start_time": "2022-12-02T07:03:27.173038",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4adb377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:07.617726Z",
     "iopub.status.busy": "2022-12-02T07:04:07.616460Z",
     "iopub.status.idle": "2022-12-02T07:04:10.405221Z",
     "shell.execute_reply": "2022-12-02T07:04:10.404105Z"
    },
    "papermill": {
     "duration": 2.841804,
     "end_time": "2022-12-02T07:04:10.408059",
     "exception": false,
     "start_time": "2022-12-02T07:04:07.566255",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.430356Z",
     "start_time": "2024-10-09T12:42:22.416388Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# import scipy.misc\n",
    "\n",
    "try:\n",
    "    from StringIO import StringIO # Python 2.7\n",
    "except ImportError:\n",
    "    from io import BytesIO # Python 3.x\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "class Logger(object):\n",
    "    def __init__(self, log_dir):\n",
    "        \"\"\"Create a summary writer logging to log_dir.\"\"\"\n",
    "        self.writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "    def scalar_summary(self, tag, value, step):\n",
    "        \"\"\"Log a scalar variable.\"\"\"\n",
    "        # summary = tf.Summary(value=[tf.Summary.Value(tag=tag, simple_value=value)])\n",
    "        # self.writer.add_summary(summary, step)\n",
    "        tf.summary.scalar(tag, value, step=step)\n",
    "        self.writer.flush()\n",
    "\n",
    "    def image_summary(self, tag, images, step):\n",
    "        \"\"\"Log a list of images.\"\"\"\n",
    "\n",
    "        img_summaries = []\n",
    "        for i, img in enumerate(images):\n",
    "            # Write the image to a string\n",
    "            try:\n",
    "                s = StringIO()\n",
    "            except:\n",
    "                s = BytesIO()\n",
    "#             scipy.misc.toimage(img).save(s, format=\"png\")\n",
    "            Image.fromarray((img*255).astype(np.uint8)).save(s,format='png')\n",
    "            # Create an Image object\n",
    "        #     img_sum = tf.summary.Image(encoded_image_string=s.getvalue(),\n",
    "        #                                height=img.shape[0],\n",
    "        #                                width=img.shape[1])\n",
    "        #     # Create a Summary value\n",
    "        #     img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "        # \n",
    "        # # Create and write Summary\n",
    "        # summary = tf.summary(value=img_summaries)\n",
    "        # self.writer.add_summary(summary, step)\n",
    "            img_str = s.getvalue()\n",
    "\n",
    "        # TensorFlow 2.x 中不再使用 tf.Summary.Image，改用 tf.summary.image\n",
    "        # 替换原来的 tf.Summary.Image 逻辑\n",
    "            tf_image = tf.image.decode_png(img_str, channels=3)  # 将字节流解码为图片\n",
    "            tf.summary.image(f'{tag}/{i}', tf.expand_dims(tf_image, 0), step=step)\n",
    "        \n",
    "            # 在 TensorFlow 2.x 中不再需要 tf.Summary.Value，因此这里略去\n",
    "            # img_summaries.append(tf.Summary.Value(tag='%s/%d' % (tag, i), image=img_sum))\n",
    "        \n",
    "        # TensorFlow 2.x 不再使用 tf.Summary，因此不需要创建和写入 Summary\n",
    "        # summary = tf.Summary(value=img_summaries)\n",
    "        # self.writer.add_summary(summary, step)\n",
    "        self.writer.flush()  # 确保写入\n",
    "\n",
    "    def histo_summary(self, tag, values, step, bins=1000):\n",
    "        \"\"\"Log a histogram of the tensor of values.\"\"\"\n",
    "\n",
    "        # Create a histogram using numpy\n",
    "        counts, bin_edges = np.histogram(values, bins=bins)\n",
    "\n",
    "        # Fill the fields of the histogram proto\n",
    "        hist = tf.HistogramProto()\n",
    "        hist.min = float(np.min(values))\n",
    "        hist.max = float(np.max(values))\n",
    "        hist.num = int(np.prod(values.shape))\n",
    "        hist.sum = float(np.sum(values))\n",
    "        hist.sum_squares = float(np.sum(values ** 2))\n",
    "\n",
    "        # Drop the start of the first bin\n",
    "        bin_edges = bin_edges[1:]\n",
    "\n",
    "        # Add bin edges and counts\n",
    "        for edge in bin_edges:\n",
    "            hist.bucket_limit.append(edge)\n",
    "        for c in counts:\n",
    "            hist.bucket.append(c)\n",
    "\n",
    "        # Create and write Summary\n",
    "        # summary = tf.Summary(value=[tf.Summary.Value(tag=tag, histo=hist)])\n",
    "        # self.writer.add_summary(summary, step)\n",
    "        tf.summary.histogram(tag, hist, step=step)\n",
    "        self.writer.flush()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ab6be7",
   "metadata": {
    "papermill": {
     "duration": 0.018247,
     "end_time": "2022-12-02T07:04:10.445921",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.427674",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "00cdb197",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.486590Z",
     "iopub.status.busy": "2022-12-02T07:04:10.485858Z",
     "iopub.status.idle": "2022-12-02T07:04:10.497206Z",
     "shell.execute_reply": "2022-12-02T07:04:10.496111Z"
    },
    "papermill": {
     "duration": 0.033082,
     "end_time": "2022-12-02T07:04:10.499427",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.466345",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.445905Z",
     "start_time": "2024-10-09T12:42:22.431352Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'\n",
    "\n",
    "# ----------------------------\n",
    "# config\n",
    "# ----------------------------\n",
    "parser = argparse.ArgumentParser(description='Training code')\n",
    "parser.add_argument('--model', default='PortraitNet', type=str,\n",
    "                    help='<model> should in [PortraitNet, ENet, BiSeNet]')\n",
    "# parser.add_argument('--config_path',\n",
    "#                     default='/home/dongx12/PortraitNet/config/model_mobilenetv2_without_auxiliary_losses.yaml',\n",
    "#                     type=str, help='the config path of the model')\n",
    "parser.add_argument('--config_path',\n",
    "                    default='E:\\Python\\ImageProcessing\\PortraitNetReproduce\\PortraitNet\\config\\model_mobilenetv2_without_auxiliary_losses.yaml',\n",
    "                    type=str, help='the config path of the model')\n",
    "parser.add_argument('--workers', default=0, type=int,\n",
    "                    help='number of data loading workers')\n",
    "parser.add_argument('--batchsize', default=64,\n",
    "                    type=int, help='mini-batch size')\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                    help='initial learning rate')\n",
    "parser.add_argument('--momentum', default=0.9, type=float, help='momentum')\n",
    "parser.add_argument('--weightdecay', default=5e-4,\n",
    "                    type=float, help='weight decay')\n",
    "parser.add_argument('--printfreq', default=100,\n",
    "                    type=int, help='print frequency')\n",
    "parser.add_argument('--savefreq', default=1000,\n",
    "                    type=int, help='save frequency')\n",
    "parser.add_argument('--resume', default=False, type=bool, help='resume')\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6c670c",
   "metadata": {
    "papermill": {
     "duration": 0.018312,
     "end_time": "2022-12-02T07:04:10.536475",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.518163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "83041478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.577373Z",
     "iopub.status.busy": "2022-12-02T07:04:10.577075Z",
     "iopub.status.idle": "2022-12-02T07:04:10.585860Z",
     "shell.execute_reply": "2022-12-02T07:04:10.584657Z"
    },
    "papermill": {
     "duration": 0.03202,
     "end_time": "2022-12-02T07:04:10.587874",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.555854",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.461358Z",
     "start_time": "2024-10-09T12:42:22.446901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading config <============\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# main\n",
    "# ----------------------------\n",
    "cudnn.benchmark = True\n",
    "assert args.model in ['PortraitNet', 'ENet',\n",
    "                      'BiSeNet'], 'Error!, <model> should in [PortraitNet, ENet, BiSeNet]'\n",
    "print('===========> loading config <============')\n",
    "exp_args = edict()\n",
    "exp_args.istrain = True\n",
    "exp_args.task = 'seg'  # only support 'seg' now\n",
    "exp_args.datasetlist = ['EG1800']\n",
    "exp_args.model_root = 'E:/Python/ImageProcessing/PortraitNetReproduce/PortraitNet/myexp/eg1800/three_224_without_group/'\n",
    "exp_args.data_root = 'E:/Python/ImageProcessing/PortraitNetReproduce/Data/'\n",
    "exp_args.file_root = 'E:/Python/ImageProcessing/PortraitNetReproduce/PortraitNet/data/select_data/'\n",
    "\n",
    "# set log path\n",
    "logs_path = os.path.join(exp_args.model_root, 'log/')\n",
    "if os.path.exists(logs_path):\n",
    "    shutil.rmtree(logs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "98a4eb8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.624758Z",
     "iopub.status.busy": "2022-12-02T07:04:10.623855Z",
     "iopub.status.idle": "2022-12-02T07:04:10.630027Z",
     "shell.execute_reply": "2022-12-02T07:04:10.629186Z"
    },
    "papermill": {
     "duration": 0.026825,
     "end_time": "2022-12-02T07:04:10.632103",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.605278",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.493300Z",
     "start_time": "2024-10-09T12:42:22.461358Z"
    }
   },
   "outputs": [],
   "source": [
    "logger_train = Logger(logs_path + 'train')\n",
    "logger_test = Logger(logs_path + 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "015c72b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.671869Z",
     "iopub.status.busy": "2022-12-02T07:04:10.671582Z",
     "iopub.status.idle": "2022-12-02T07:04:10.680028Z",
     "shell.execute_reply": "2022-12-02T07:04:10.679010Z"
    },
    "papermill": {
     "duration": 0.032142,
     "end_time": "2022-12-02T07:04:10.682088",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.649946",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.507249Z",
     "start_time": "2024-10-09T12:42:22.494783Z"
    }
   },
   "outputs": [],
   "source": [
    "# the height of input images, default=224\n",
    "exp_args.input_height = 224\n",
    "# the width of input images, default=224\n",
    "exp_args.input_width =224\n",
    "\n",
    "# if exp_args.video=True, add prior channel for input images, default=False\n",
    "exp_args.video = False\n",
    "# the probability to set empty prior channel, default=0.5\n",
    "exp_args.prior_prob = 0.5\n",
    "\n",
    "# whether to add boundary auxiliary loss, default=False\n",
    "exp_args.addEdge = False\n",
    "# the weight of boundary auxiliary loss, default=0.1\n",
    "exp_args.edgeRatio = 0.1\n",
    "# whether to add consistency constraint loss, default=False\n",
    "exp_args.stability = False\n",
    "# whether to use KL loss in consistency constraint loss, default=True\n",
    "exp_args.use_kl = True\n",
    "# temperature in consistency constraint loss, default=1\n",
    "exp_args.temperature = 1\n",
    "# the weight of consistency constraint loss, default=2\n",
    "exp_args.alpha = 2\n",
    "\n",
    "# input normalization parameters\n",
    "exp_args.padding_color = 128\n",
    "exp_args.img_scale = 1\n",
    "# BGR order, image mean, default=[103.94, 116.78, 123.68]\n",
    "exp_args.img_mean = [103.94, 116.78, 123.68]\n",
    "# BGR order, image val, default=[1/0.017, 1/0.017, 1/0.017]\n",
    "exp_args.img_val =  [0.017, 0.017, 0.017]\n",
    "\n",
    "# whether to use pretian model to init portraitnet,default true\n",
    "exp_args.init = True\n",
    "# whether to continue training\n",
    "exp_args.resume = False\n",
    "\n",
    "# if exp_args.useUpsample==True, use nn.Upsample in decoder, else use nn.ConvTranspose2d\n",
    "exp_args.useUpsample = False\n",
    "# if exp_args.useDeconvGroup==True, set groups=input_channel in nn.ConvTranspose2d\n",
    "exp_args.useDeconvGroup = False\n",
    "\n",
    "# set training dataset\n",
    "exp_args.istrain = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6f59d",
   "metadata": {
    "papermill": {
     "duration": 0.017545,
     "end_time": "2022-12-02T07:04:10.717331",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.699786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# set training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "01bcffc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.753885Z",
     "iopub.status.busy": "2022-12-02T07:04:10.753590Z",
     "iopub.status.idle": "2022-12-02T07:04:10.766791Z",
     "shell.execute_reply": "2022-12-02T07:04:10.765842Z"
    },
    "papermill": {
     "duration": 0.034032,
     "end_time": "2022-12-02T07:04:10.768931",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.734899",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.522755Z",
     "start_time": "2024-10-09T12:42:22.512738Z"
    }
   },
   "outputs": [],
   "source": [
    "exp_args.istrain = True\n",
    "# ------------------- Dataset -------------------\n",
    "dataset_train = Human(exp_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3af61adc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.806948Z",
     "iopub.status.busy": "2022-12-02T07:04:10.806186Z",
     "iopub.status.idle": "2022-12-02T07:04:10.818478Z",
     "shell.execute_reply": "2022-12-02T07:04:10.817413Z"
    },
    "papermill": {
     "duration": 0.033166,
     "end_time": "2022-12-02T07:04:10.820763",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.787597",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:22.537727Z",
     "start_time": "2024-10-09T12:42:22.523755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image number in training:  1447\n",
      "image number in testing:  289\n",
      "finish load dataset ...\n"
     ]
    }
   ],
   "source": [
    "#((3, 224, 224), (3, 224, 224), (224, 224), (224, 224))\n",
    "print(\"image number in training: \", len(dataset_train))\n",
    "dataLoader_train = torch.utils.data.DataLoader(dataset_train, batch_size=args.batchsize,\n",
    "                                               shuffle=True, num_workers=args.workers)\n",
    "exp_args.istrain = False\n",
    "dataset_test = Human(exp_args)\n",
    "print(\"image number in testing: \", len(dataset_test))\n",
    "dataLoader_test = torch.utils.data.DataLoader(dataset_test, batch_size=1,\n",
    "                                              shuffle=False, num_workers=args.workers)\n",
    "\n",
    "exp_args.istrain = True\n",
    "print(\"finish load dataset ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3c55d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:10.860542Z",
     "iopub.status.busy": "2022-12-02T07:04:10.859781Z",
     "iopub.status.idle": "2022-12-02T07:04:18.286785Z",
     "shell.execute_reply": "2022-12-02T07:04:18.285183Z"
    },
    "papermill": {
     "duration": 7.451118,
     "end_time": "2022-12-02T07:04:18.289592",
     "exception": false,
     "start_time": "2022-12-02T07:04:10.838474",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-10T09:06:19.831954Z",
     "start_time": "2024-10-10T09:06:19.172343Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataLoader_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m input_ori, \u001B[38;5;28minput\u001B[39m, edge, mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdataLoader_train\u001B[49m))\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataLoader_train' is not defined"
     ]
    }
   ],
   "source": [
    "input_ori, input, edge, mask = next(iter(dataLoader_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7cd26479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:18.331583Z",
     "iopub.status.busy": "2022-12-02T07:04:18.330493Z",
     "iopub.status.idle": "2022-12-02T07:04:18.340744Z",
     "shell.execute_reply": "2022-12-02T07:04:18.339704Z"
    },
    "papermill": {
     "duration": 0.033504,
     "end_time": "2022-12-02T07:04:18.343047",
     "exception": false,
     "start_time": "2022-12-02T07:04:18.309543",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:24.237165Z",
     "start_time": "2024-10-09T12:42:24.223581Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([64, 3, 224, 224])"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e53109",
   "metadata": {
    "papermill": {
     "duration": 0.019182,
     "end_time": "2022-12-02T07:04:18.381514",
     "exception": false,
     "start_time": "2022-12-02T07:04:18.362332",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f2c67b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:18.421869Z",
     "iopub.status.busy": "2022-12-02T07:04:18.421529Z",
     "iopub.status.idle": "2022-12-02T07:04:18.480546Z",
     "shell.execute_reply": "2022-12-02T07:04:18.479668Z"
    },
    "papermill": {
     "duration": 0.081986,
     "end_time": "2022-12-02T07:04:18.482796",
     "exception": false,
     "start_time": "2022-12-02T07:04:18.400810",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:24.268494Z",
     "start_time": "2024-10-09T12:42:24.238972Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "  \n",
    "def make_bilinear_weights(size, num_channels):\n",
    "    ''' Make a 2D bilinear kernel suitable for upsampling\n",
    "    Stack the bilinear kernel for application to tensor '''\n",
    "    factor = (size + 1) // 2\n",
    "    if size % 2 == 1:\n",
    "        center = factor - 1\n",
    "    else:\n",
    "        center = factor - 0.5\n",
    "    og = np.ogrid[:size, :size]\n",
    "    filt = (1 - abs(og[0] - center) / factor) * \\\n",
    "           (1 - abs(og[1] - center) / factor)\n",
    "\n",
    "    # print filt\n",
    "    filt = torch.from_numpy(filt)\n",
    "    w = torch.zeros(num_channels, 1, size, size)\n",
    "    for i in range(num_channels):\n",
    "        w[i, 0] = filt\n",
    "    return w    \n",
    "    \n",
    "# 1x1 Convolution\n",
    "def conv_1x1(inp, oup):\n",
    "    \"\"\"1x1 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "\n",
    "def conv_1x1_bn(inp, oup):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "        nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_bn(inp, oup, kernel, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=kernel, stride=stride, padding=int((kernel-1)/2), bias=False),\n",
    "        nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "def conv_dw(inp, oup, kernel, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, inp, kernel, stride, int((kernel-1)/2), groups=inp, bias=False),\n",
    "        nn.BatchNorm2d(num_features=inp, eps=1e-05, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
    "        nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio, dilation=1):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            # pw\n",
    "            nn.Conv2d(inp, inp * expand_ratio, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=inp * expand_ratio, eps=1e-05, momentum=0.1, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # dw\n",
    "            nn.Conv2d(inp * expand_ratio, inp * expand_ratio, \n",
    "                      kernel_size=3, stride=stride, padding=dilation, dilation=dilation,\n",
    "                      groups=inp * expand_ratio, bias=False),\n",
    "            nn.BatchNorm2d(num_features=inp * expand_ratio, eps=1e-05, momentum=0.1, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(inp * expand_ratio, oup, kernel_size=1, stride=1, padding=0, dilation=1, groups=1, bias=False),\n",
    "            nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)\n",
    "        \n",
    "        \n",
    "# Residual Block\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inp, oup, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        \n",
    "        self.block = nn.Sequential(\n",
    "            conv_dw(inp, oup, 3, stride=stride),\n",
    "            nn.Conv2d(in_channels=oup, out_channels=oup, kernel_size=3, stride=1, padding=1, groups=oup, bias=False),\n",
    "            nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=oup, out_channels=oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "        )\n",
    "        if inp == oup:\n",
    "            self.residual = None\n",
    "        else:\n",
    "            self.residual = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=inp, out_channels=oup, kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(num_features=oup, eps=1e-05, momentum=0.1, affine=True),\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        \n",
    "        out = self.block(x)\n",
    "        if self.residual is not None:\n",
    "            residual = self.residual(x)\n",
    "            \n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, n_class=2, useUpsample=False, useDeconvGroup=False, addEdge=False, \n",
    "                 channelRatio=1.0, minChannel=16, weightInit=True, video=False):\n",
    "        super(MobileNetV2, self).__init__()\n",
    "        '''\n",
    "        # setting of inverted residual blocks\n",
    "        self.interverted_residual_setting = [\n",
    "            # t, c, n, s\n",
    "            [1, 16, 1, 1],\n",
    "            [6, 24, 2, 2],\n",
    "            [6, 32, 3, 2],\n",
    "            [6, 64, 4, 2],\n",
    "            [6, 96, 3, 1],\n",
    "            [6, 160, 3, 2],\n",
    "            [6, 320, 1, 1],\n",
    "        ]\n",
    "        '''\n",
    "        self.addEdge = addEdge\n",
    "        self.channelRatio = channelRatio\n",
    "        self.minChannel = minChannel\n",
    "        self.useDeconvGroup = useDeconvGroup\n",
    "        \n",
    "        if video == True:\n",
    "            self.stage0 = conv_bn(4, self.depth(32), 3, 2)\n",
    "        else:\n",
    "            self.stage0 = conv_bn(3, self.depth(32), 3, 2)\n",
    "        \n",
    "        self.stage1 = InvertedResidual(self.depth(32), self.depth(16), 1, 1) # 1/2\n",
    "        \n",
    "        self.stage2 = nn.Sequential( # 1/4\n",
    "            InvertedResidual(self.depth(16), self.depth(24), 2, 6),\n",
    "            InvertedResidual(self.depth(24), self.depth(24), 1, 6),\n",
    "        )\n",
    "        \n",
    "        self.stage3 = nn.Sequential( # 1/8\n",
    "            InvertedResidual(self.depth(24), self.depth(32), 2, 6),\n",
    "            InvertedResidual(self.depth(32), self.depth(32), 1, 6),\n",
    "            InvertedResidual(self.depth(32), self.depth(32), 1, 6),\n",
    "        )\n",
    "        \n",
    "        self.stage4 = nn.Sequential( # 1/16\n",
    "            InvertedResidual(self.depth(32), self.depth(64), 2, 6),\n",
    "            InvertedResidual(self.depth(64), self.depth(64), 1, 6),\n",
    "            InvertedResidual(self.depth(64), self.depth(64), 1, 6),\n",
    "            InvertedResidual(self.depth(64), self.depth(64), 1, 6),\n",
    "        )\n",
    "        \n",
    "        self.stage5 = nn.Sequential( # 1/16\n",
    "            InvertedResidual(self.depth(64), self.depth(96), 1, 6),\n",
    "            InvertedResidual(self.depth(96), self.depth(96), 1, 6),\n",
    "            InvertedResidual(self.depth(96), self.depth(96), 1, 6),\n",
    "        )\n",
    "        \n",
    "        self.stage6 = nn.Sequential( # 1/32\n",
    "            InvertedResidual(self.depth(96), self.depth(160), 2, 6),\n",
    "            InvertedResidual(self.depth(160), self.depth(160), 1, 6),\n",
    "            InvertedResidual(self.depth(160), self.depth(160), 1, 6),\n",
    "        )\n",
    "        \n",
    "        self.stage7 = InvertedResidual(self.depth(160), self.depth(320), 1, 6) # 1/32\n",
    "        \n",
    "        \n",
    "        if useUpsample == True:\n",
    "            self.deconv1 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            self.deconv2 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            self.deconv3 = nn.Upsample(scale_factor=2, mode='bilinear')    \n",
    "            self.deconv4 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "            self.deconv5 = nn.Upsample(scale_factor=2, mode='bilinear')\n",
    "        else:\n",
    "            if useDeconvGroup == True:\n",
    "                self.deconv1 = nn.ConvTranspose2d(self.depth(96), self.depth(96), groups=self.depth(96), \n",
    "                                                  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv2 = nn.ConvTranspose2d(self.depth(32), self.depth(32), groups=self.depth(32), \n",
    "                                                  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv3 = nn.ConvTranspose2d(self.depth(24), self.depth(24), groups=self.depth(24), \n",
    "                                                  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv4 = nn.ConvTranspose2d(self.depth(16), self.depth(16), groups=self.depth(16), \n",
    "                                                  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv5 = nn.ConvTranspose2d(self.depth(8),  self.depth(8),  groups=self.depth(8),  \n",
    "                                                  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "            else:\n",
    "                self.deconv1 = nn.ConvTranspose2d(self.depth(96), self.depth(96), \n",
    "                                                  groups=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv2 = nn.ConvTranspose2d(self.depth(32), self.depth(32), \n",
    "                                                  groups=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv3 = nn.ConvTranspose2d(self.depth(24), self.depth(24), \n",
    "                                                  groups=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv4 = nn.ConvTranspose2d(self.depth(16), self.depth(16), \n",
    "                                                  groups=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "                self.deconv5 = nn.ConvTranspose2d(self.depth(8),  self.depth(8),  \n",
    "                                                  groups=1, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        \n",
    "        self.transit1 = ResidualBlock(self.depth(320), self.depth(96))\n",
    "        self.transit2 = ResidualBlock(self.depth(96),  self.depth(32))\n",
    "        self.transit3 = ResidualBlock(self.depth(32),  self.depth(24))\n",
    "        self.transit4 = ResidualBlock(self.depth(24),  self.depth(16))\n",
    "        self.transit5 = ResidualBlock(self.depth(16),  self.depth(8))\n",
    "        \n",
    "        self.pred = nn.Conv2d(self.depth(8), n_class, 3, 1, 1, bias=False)\n",
    "        if self.addEdge == True:\n",
    "            self.edge = nn.Conv2d(self.depth(8), n_class, 3, 1, 1, bias=False)\n",
    "        \n",
    "        if weightInit == True:\n",
    "            self._initialize_weights()\n",
    "            \n",
    "    def depth(self, channels):\n",
    "        min_channel = min(channels, self.minChannel)\n",
    "        return max(min_channel, int(channels*self.channelRatio))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        feature_1_2  = self.stage0(x)\n",
    "        feature_1_2  = self.stage1(feature_1_2)\n",
    "        feature_1_4  = self.stage2(feature_1_2)\n",
    "        feature_1_8  = self.stage3(feature_1_4)\n",
    "        feature_1_16 = self.stage4(feature_1_8)\n",
    "        feature_1_16 = self.stage5(feature_1_16)\n",
    "        feature_1_32 = self.stage6(feature_1_16)\n",
    "        feature_1_32 = self.stage7(feature_1_32)\n",
    "        \n",
    "        up_1_16 = self.deconv1(self.transit1(feature_1_32))\n",
    "        up_1_8  = self.deconv2(self.transit2(feature_1_16 + up_1_16))\n",
    "        up_1_4  = self.deconv3(self.transit3(feature_1_8 + up_1_8))\n",
    "        up_1_2  = self.deconv4(self.transit4(feature_1_4 + up_1_4))\n",
    "        up_1_1  = self.deconv5(self.transit5(up_1_2))\n",
    "        \n",
    "        pred = self.pred(up_1_1)\n",
    "        if self.addEdge == True:\n",
    "            edge = self.edge(up_1_1)\n",
    "            return pred, edge\n",
    "        else:\n",
    "            return pred\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.ConvTranspose2d):\n",
    "                assert m.kernel_size[0] == m.kernel_size[1]\n",
    "                initial_weight = make_bilinear_weights(m.kernel_size[0], m.out_channels) # same as caffe\n",
    "                m.weight.data.copy_(initial_weight)\n",
    "                if self.useDeconvGroup == True:\n",
    "                    m.requires_grad = False # use deconvolution as bilinear upsample\n",
    "                    print (\"freeze deconv\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "5fe17722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:18.521546Z",
     "iopub.status.busy": "2022-12-02T07:04:18.519853Z",
     "iopub.status.idle": "2022-12-02T07:04:21.874910Z",
     "shell.execute_reply": "2022-12-02T07:04:21.873458Z"
    },
    "papermill": {
     "duration": 3.376666,
     "end_time": "2022-12-02T07:04:21.877389",
     "exception": false,
     "start_time": "2022-12-02T07:04:18.500723",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:24.395361Z",
     "start_time": "2024-10-09T12:42:24.269491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========> loading model <===========\n",
      "finish load PortraitNet ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\docking\\AppData\\Local\\Temp\\ipykernel_23420\\1602237901.py:257: FutureWarning: `nn.init.kaiming_normal` is now deprecated in favor of `nn.init.kaiming_normal_`.\n",
      "  nn.init.kaiming_normal(m.weight.data)\n"
     ]
    }
   ],
   "source": [
    "print('===========> loading model <===========')\n",
    "if args.model == 'PortraitNet':\n",
    "    # train our model: portraitnet\n",
    "#     import model_mobilenetv2_seg_small as modellib\n",
    "    netmodel = MobileNetV2(n_class=2,\n",
    "                            useUpsample=exp_args.useUpsample,\n",
    "                            useDeconvGroup=exp_args.useDeconvGroup,\n",
    "                            addEdge=exp_args.addEdge,\n",
    "                            channelRatio=1.0,\n",
    "                            minChannel=16,\n",
    "                            weightInit=True,\n",
    "                            video=exp_args.video).cuda()\n",
    "    netmodel = torch.nn.DataParallel(netmodel).cuda()\n",
    "    print(\"finish load PortraitNet ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "206c900a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:21.915550Z",
     "iopub.status.busy": "2022-12-02T07:04:21.915235Z",
     "iopub.status.idle": "2022-12-02T07:04:21.927496Z",
     "shell.execute_reply": "2022-12-02T07:04:21.926479Z"
    },
    "papermill": {
     "duration": 0.033454,
     "end_time": "2022-12-02T07:04:21.929597",
     "exception": false,
     "start_time": "2022-12-02T07:04:21.896143",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:24.410838Z",
     "start_time": "2024-10-09T12:42:24.396358Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_parameters(model, args, useDeconvGroup=True):\n",
    "    lr_0 = []\n",
    "    lr_1 = []\n",
    "    params_dict = dict(model.named_parameters())\n",
    "    for key, value in params_dict.items():\n",
    "        if 'deconv' in key and useDeconvGroup == True:\n",
    "            print(\"useDeconvGroup=True, lr=0, key: \", key)\n",
    "            lr_0.append(value)\n",
    "        else:\n",
    "            lr_1.append(value)\n",
    "    params = [{'params': lr_0, 'lr': args.lr * 0},\n",
    "              {'params': lr_1, 'lr': args.lr * 1}]\n",
    "    return params, [0., 1.]\n",
    "\n",
    "\n",
    "params, multiple = get_parameters(\n",
    "    netmodel, args, useDeconvGroup=exp_args.useDeconvGroup)\n",
    "optimizer = torch.optim.Adam(params, args.lr, weight_decay=args.weightdecay)\n",
    "# if exp_args.init == True:\n",
    "#     pretrained_state_dict = torch.load('pretrained_mobilenetv2_base.pth')\n",
    "#     pretrained_state_dict_keys = pretrained_state_dict.keys()\n",
    "#     netmodel_state_dict = netmodel.state_dict()\n",
    "#     netmodel_state_dict_keys = netmodel.state_dict().keys()\n",
    "#     print (\"pretrain keys: \", len(pretrained_state_dict_keys))\n",
    "#     print (\"netmodel keys: \", len(netmodel_state_dict_keys))\n",
    "#     weights_load = {}\n",
    "#     for k in range(len(pretrained_state_dict_keys)):\n",
    "#         if pretrained_state_dict[pretrained_state_dict_keys[k]].shape == \\\n",
    "#         netmodel_state_dict[netmodel_state_dict_keys[k]].shape:\n",
    "#             weights_load[netmodel_state_dict_keys[k]] = pretrained_state_dict[pretrained_state_dict_keys[k]]\n",
    "#             print ('init model', netmodel_state_dict_keys[k],\n",
    "#                     'from pretrained', pretrained_state_dict_keys[k])\n",
    "#         else:\n",
    "#             break\n",
    "#     print (\"init len is:\", len(weights_load))\n",
    "#     netmodel_state_dict.update(weights_load)\n",
    "#     netmodel.load_state_dict(netmodel_state_dict)\n",
    "#     print (\"load model init finish...\")\n",
    "if exp_args.resume:\n",
    "    bestModelFile = os.path.join(exp_args.model_root, 'model_best.pth.tar')\n",
    "    if os.path.isfile(bestModelFile):\n",
    "        checkpoint = torch.load(bestModelFile)\n",
    "        netmodel.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        gap = checkpoint['epoch']\n",
    "        minLoss = checkpoint['minLoss']\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(\n",
    "            bestModelFile, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(bestModelFile))\n",
    "else:\n",
    "    minLoss = 10000\n",
    "    gap = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dbf565a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:21.968138Z",
     "iopub.status.busy": "2022-12-02T07:04:21.966495Z",
     "iopub.status.idle": "2022-12-02T07:04:22.053675Z",
     "shell.execute_reply": "2022-12-02T07:04:22.052686Z"
    },
    "papermill": {
     "duration": 0.108359,
     "end_time": "2022-12-02T07:04:22.055866",
     "exception": false,
     "start_time": "2022-12-02T07:04:21.947507",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T12:42:24.584924Z",
     "start_time": "2024-10-09T12:42:24.411835Z"
    }
   },
   "outputs": [],
   "source": [
    "def calcIOU(img, mask):\n",
    "    sum1 = img + mask\n",
    "    sum1[sum1>0] = 1\n",
    "    sum2 = img + mask\n",
    "    sum2[sum2<2] = 0\n",
    "    sum2[sum2>=2] = 1\n",
    "    if np.sum(sum1) == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 1.0*np.sum(sum2)/np.sum(sum1)\n",
    "\n",
    "def get_parameters(model, args, useDeconvGroup=True):\n",
    "    lr_0 = []\n",
    "    lr_1 = []\n",
    "    params_dict = dict(model.named_parameters())\n",
    "    for key, value in params_dict.items():\n",
    "        if 'deconv' in key and useDeconvGroup==True:\n",
    "            print (\"useDeconvGroup=True, lr=0, key: \", key)\n",
    "            lr_0.append(value)\n",
    "        else:\n",
    "            lr_1.append(value)\n",
    "    params = [{'params': lr_0, 'lr': args.lr * 0},\n",
    "              {'params': lr_1, 'lr': args.lr * 1}]\n",
    "    return params, [0., 1.]\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args, multiple):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 0.95 every 20 epochs\"\"\"\n",
    "    # lr = args.lr * (0.95 ** (epoch // 4))\n",
    "    lr = args.lr * (0.95 ** (epoch // 20))\n",
    "    for i, param_group in enumerate(optimizer.param_groups):\n",
    "        param_group['lr'] = lr * multiple[i]\n",
    "    pass\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    pass\n",
    "\n",
    "def loss_KL(student_outputs, teacher_outputs, T):\n",
    "    \"\"\"\n",
    "    Code referenced from: \n",
    "    https://github.com/peterliht/knowledge-distillation-pytorch/blob/master/model/net.py\n",
    "    \n",
    "    Compute the knowledge-distillation (KD) loss given outputs, labels.\n",
    "    \"Hyperparameters\": temperature and alpha\n",
    "    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher\n",
    "    and student expects the input tensor to be log probabilities! See Issue #2\n",
    "    \"\"\"\n",
    "    KD_loss = nn.KLDivLoss()(F.log_softmax(student_outputs/T, dim=1), \n",
    "                             F.softmax(teacher_outputs/T, dim=1)) * T * T\n",
    "    return KD_loss\n",
    "\n",
    "\n",
    "def test(dataLoader, netmodel, optimizer, epoch, logger, exp_args):\n",
    "    batch_time = AverageMeter('batch_time')\n",
    "    data_time = AverageMeter('data_time')\n",
    "    losses = AverageMeter('losses')\n",
    "    \n",
    "    losses_mask_ori = AverageMeter('losses_mask_ori')\n",
    "    losses_mask = AverageMeter('losses_mask')\n",
    "    \n",
    "    losses_edge_ori = AverageMeter('losses_edge_ori')\n",
    "    losses_edge = AverageMeter('losses_edge')\n",
    "    \n",
    "    losses_stability_mask = AverageMeter('losses_stability_mask')\n",
    "    losses_stability_edge = AverageMeter('losses_stability_edge')\n",
    "    \n",
    "    # switch to eval mode\n",
    "    netmodel.eval()\n",
    "    \n",
    "    loss_Softmax = nn.CrossEntropyLoss(ignore_index=255) # mask loss\n",
    "    loss_Focalloss = FocalLoss(gamma=2) # edge loss\n",
    "    loss_l2 = nn.MSELoss() # edge loss\n",
    "    \n",
    "    end = time.time()\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    iou = 0\n",
    "    \n",
    "    for i, (input_ori, input, edge, mask) in enumerate(dataLoader):  \n",
    "        data_time.update(time.time() - end)\n",
    "        input_ori_var = Variable(input_ori.cuda())\n",
    "        input_var = Variable(input.cuda())\n",
    "        edge_var = Variable(edge.cuda())\n",
    "        mask_var = Variable(mask.cuda())\n",
    "        \n",
    "        if exp_args.addEdge == True:\n",
    "            output_mask, output_edge = netmodel(input_var)\n",
    "            loss_mask = loss_Softmax(output_mask, mask_var)\n",
    "            losses_mask.update(loss_mask.item(), input.size(0))\n",
    "            # loss_edge = loss_l2(output_edge, edge_var) * exp_args.edgeRatio\n",
    "            loss_edge = loss_Focalloss(output_edge, edge_var) * exp_args.edgeRatio\n",
    "            losses_edge.update(loss_edge.item(), input.size(0))\n",
    "            loss = loss_mask + loss_edge\n",
    "            \n",
    "            if exp_args.stability == True:\n",
    "                output_mask_ori, output_edge_ori = netmodel(input_ori_var)\n",
    "                loss_mask_ori = loss_Softmax(output_mask_ori, mask_var)\n",
    "                losses_mask_ori.update(loss_mask_ori.item(), input.size(0))\n",
    "                # loss_edge_ori = loss_l2(output_edge_ori, edge_var) * exp_args.edgeRatio\n",
    "                loss_edge_ori = loss_Focalloss(output_edge_ori, edge_var) * exp_args.edgeRatio\n",
    "                losses_edge_ori.update(loss_edge_ori.item(), input.size(0))\n",
    "                \n",
    "                if exp_args.use_kl == False:\n",
    "                    # consistency constraint loss: L2 distance \n",
    "                    loss_stability_mask = loss_l2(output_mask, \n",
    "                                                  Variable(output_mask_ori.data, \n",
    "                                                           requires_grad = False)) * exp_args.alpha\n",
    "                    loss_stability_edge = loss_l2(output_edge, \n",
    "                                                  Variable(output_edge_ori.data, \n",
    "                                                           requires_grad = False)) * exp_args.alpha * exp_args.edgeRatio\n",
    "                else:\n",
    "                    # consistency constraint loss: KL distance\n",
    "                    loss_stability_mask = loss_KL(output_mask, \n",
    "                                                  Variable(output_mask_ori.data, requires_grad = False), \n",
    "                                                  exp_args.temperature) * exp_args.alpha\n",
    "                    loss_stability_edge = loss_KL(output_edge, \n",
    "                                                  Variable(output_edge_ori.data, requires_grad = False), \n",
    "                                                  exp_args.temperature) * exp_args.alpha * exp_args.edgeRatio\n",
    "                    \n",
    "                losses_stability_mask.update(loss_stability_mask.item(), input.size(0))\n",
    "                losses_stability_edge.update(loss_stability_edge.item(), input.size(0))\n",
    "                \n",
    "                # total loss\n",
    "                # loss = loss_mask + loss_mask_ori + loss_edge + loss_edge_ori + loss_stability_mask + loss_stability_edge\n",
    "                loss = loss_mask + loss_mask_ori + loss_stability_mask + loss_edge\n",
    "        else:\n",
    "            output_mask = netmodel(input_var)\n",
    "            loss_mask = loss_Softmax(output_mask, mask_var)\n",
    "            losses_mask.update(loss_mask.item(), input.size(0))\n",
    "            loss = loss_mask\n",
    "            \n",
    "            if exp_args.stability == True:\n",
    "                # loss part2\n",
    "                output_mask_ori = netmodel(input_ori_var)\n",
    "                loss_mask_ori = loss_Softmax(output_mask_ori, mask_var)\n",
    "                losses_mask_ori.update(loss_mask_ori.item(), input.size(0))\n",
    "                if exp_args.use_kl == False:\n",
    "                    # consistency constraint loss: L2 distance\n",
    "                    loss_stability_mask = loss_l2(output_mask, \n",
    "                                                  Variable(output_mask_ori.data, \n",
    "                                                           requires_grad = False)) * exp_args.alpha\n",
    "                else:\n",
    "                    # consistency constraint loss: KL distance\n",
    "                    loss_stability_mask = loss_KL(output_mask, \n",
    "                                                  Variable(output_mask_ori.data, requires_grad = False),\n",
    "                                                  exp_args.temperature) * exp_args.alpha\n",
    "                losses_stability_mask.update(loss_stability_mask.item(), input.size(0))\n",
    "                # total loss\n",
    "                loss = loss_mask + loss_mask_ori + loss_stability_mask\n",
    "        \n",
    "        # total loss\n",
    "        loss = loss_mask\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        \n",
    "        prob = softmax(output_mask)[0,1,:,:]\n",
    "        pred = prob.data.cpu().numpy()\n",
    "        pred[pred>0.5] = 1\n",
    "        pred[pred<=0.5] = 0\n",
    "        iou += calcIOU(pred, mask_var[0].data.cpu().numpy())\n",
    "        \n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "        \n",
    "        if i % args.printfreq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Lr-deconv: [{3}]\\t'\n",
    "                  'Lr-other: [{4}]\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(dataLoader), \n",
    "                      optimizer.param_groups[0]['lr'],\n",
    "                      optimizer.param_groups[1]['lr'], \n",
    "                      loss=losses)) \n",
    "            \n",
    "        ## '===========> logger <==========='\n",
    "        # (1) Log the scalar values\n",
    "        if exp_args.addEdge == True and exp_args.stability == True:\n",
    "            info = { # batch_time.name: batch_time.val,\n",
    "                     # data_time.name: data_time.val,\n",
    "                     losses.name: losses.val,\n",
    "                     losses_mask_ori.name: losses_mask_ori.val,\n",
    "                     losses_mask.name: losses_mask.val,\n",
    "                     losses_edge_ori.name: losses_edge_ori.val,\n",
    "                     losses_edge.name: losses_edge.val,\n",
    "                     losses_stability_mask.name: losses_stability_mask.val, \n",
    "                     losses_stability_edge.name: losses_stability_edge.val\n",
    "                   }\n",
    "        elif exp_args.addEdge == True and exp_args.stability == False:\n",
    "            info = { # batch_time.name: batch_time.val,\n",
    "                     # data_time.name: data_time.val,\n",
    "                     losses.name: losses.val,\n",
    "                     losses_mask.name: losses_mask.val,\n",
    "                     losses_edge.name: losses_edge.val,\n",
    "                   }\n",
    "        elif exp_args.addEdge == False and exp_args.stability == True:\n",
    "            info = { # batch_time.name: batch_time.val,\n",
    "                     # data_time.name: data_time.val,\n",
    "                     losses.name: losses.val,\n",
    "                     losses_mask_ori.name: losses_mask_ori.val,\n",
    "                     losses_mask.name: losses_mask.val,\n",
    "                     losses_stability_mask.name: losses_stability_mask.val, \n",
    "                   }\n",
    "        elif exp_args.addEdge == False and exp_args.stability == False:\n",
    "            info = { # batch_time.name: batch_time.val,\n",
    "                     # data_time.name: data_time.val,\n",
    "                     losses.name: losses.val,\n",
    "                     losses_mask.name: losses_mask.val,\n",
    "                   }\n",
    "            \n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step=i)\n",
    "        '''\n",
    "        # (2) Log values and gradients of the parameters (histogram)\n",
    "        for tag, value in netmodel.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step=i)\n",
    "            if value.grad is None:\n",
    "                continue\n",
    "            logger.histo_summary(tag+'/grad', value.grad.cpu().data.numpy(), step=i)\n",
    "            break\n",
    "        '''\n",
    "        # (3) Log the images\n",
    "        if i % (args.printfreq) == 0:\n",
    "            num = 2\n",
    "            input_img = np.uint8((\n",
    "                        Anti_Normalize_Img(\n",
    "                            np.transpose(input.cpu().numpy()[0:num], (0, 2, 3, 1)), \n",
    "                            scale=exp_args.img_scale, \n",
    "                            mean=exp_args.img_mean, \n",
    "                            val=exp_args.img_val)))[:,:,:,:3][:,:,:,::-1]\n",
    "            \n",
    "            if exp_args.video == True:\n",
    "                input_prior = np.float32(np.transpose(input.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,3])\n",
    "            \n",
    "            input_mask = mask.cpu().numpy()[0:num]\n",
    "            input_mask[input_mask==255] = 0\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            prob = softmax(output_mask)\n",
    "            masks_pred = np.transpose(prob.data.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,1]\n",
    "            \n",
    "            info = {}\n",
    "            info['input_img'] = input_img\n",
    "            if exp_args.video == True:\n",
    "                info['input_prior'] = input_prior*255\n",
    "            info['input_mask'] = input_mask*255\n",
    "            info['output_mask'] = masks_pred*255\n",
    "\n",
    "            if exp_args.addEdge == True:\n",
    "                input_edge = edge.cpu().numpy()[0:num]\n",
    "                edge_pred = np.transpose(output_edge.data.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,0]\n",
    "                \n",
    "                if exp_args.stability == True:\n",
    "                    input_img_ori = np.uint8((\n",
    "                        Anti_Normalize_Img(\n",
    "                            np.transpose(input_ori.cpu().numpy()[0:num], (0, 2, 3, 1)), \n",
    "                            scale=exp_args.img_scale, \n",
    "                            mean=exp_args.img_mean, \n",
    "                            val=exp_args.img_val)))[:,:,:,:3][:,:,:,::-1]\n",
    "             \n",
    "                    prob_ori = softmax(output_mask_ori)\n",
    "                    masks_pred_ori = np.transpose(prob_ori.data.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,1]\n",
    "                    edge_pred_ori = np.transpose(output_edge_ori.data.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,0]\n",
    "                    \n",
    "                    info['input_img_ori'] = input_img_ori\n",
    "                    info['output_mask_ori'] = masks_pred_ori*255\n",
    "                    \n",
    "                    info['input_edge'] = input_edge*255\n",
    "                    info['output_edge'] = edge_pred*255\n",
    "                    info['output_edge_ori'] = edge_pred_ori*255\n",
    "                else:\n",
    "                    info['input_edge'] = input_edge*255\n",
    "                    info['output_edge'] = edge_pred*255\n",
    "            else:\n",
    "                if exp_args.stability == True:\n",
    "                    input_img_ori = np.uint8((\n",
    "                        Anti_Normalize_Img(\n",
    "                            np.transpose(input_ori.cpu().numpy()[0:num], (0, 2, 3, 1)), \n",
    "                            scale=exp_args.img_scale, \n",
    "                            mean=exp_args.img_mean, \n",
    "                            val=exp_args.img_val)))[:,:,:,:3][:,:,:,::-1]\n",
    "             \n",
    "                    prob_ori = softmax(output_mask_ori)\n",
    "                    masks_pred_ori = np.transpose(prob_ori.data.cpu().numpy()[0:num], (0, 2, 3, 1))[:,:,:,1]\n",
    "                    \n",
    "                    info['input_img_ori'] = input_img_ori\n",
    "                    info['output_mask_ori'] = masks_pred_ori*255\n",
    "            print (np.max(masks_pred), np.min(masks_pred))\n",
    "            \n",
    "\n",
    "            for tag, images in info.items():\n",
    "                logger.image_summary(tag, images, step=i)\n",
    "            \n",
    "    # return losses.avg\n",
    "    return 1-iou/len(dataLoader)\n",
    "\n",
    "def train(dataLoader, netmodel, optimizer, epoch, logger, exp_args):\n",
    "    batch_time = AverageMeter('batch_time')\n",
    "    data_time = AverageMeter('data_time')\n",
    "\n",
    "    losses = AverageMeter('losses')\n",
    "    losses_mask = AverageMeter('losses_mask')\n",
    "\n",
    "    if exp_args.addEdge == True:  # False\n",
    "        losses_edge_ori = AverageMeter('losses_edge_ori')\n",
    "        losses_edge = AverageMeter('losses_edge')\n",
    "\n",
    "    if exp_args.stability == True:  # False\n",
    "        losses_mask_ori = AverageMeter('losses_mask_ori')\n",
    "        losses_stability_mask = AverageMeter('losses_stability_mask')\n",
    "        losses_stability_edge = AverageMeter('losses_stability_edge')\n",
    "    netmodel.train()\n",
    "    loss_Softmax = nn.CrossEntropyLoss(ignore_index=255)  # mask loss\n",
    "    loss_Focalloss = FocalLoss(gamma=2)  # boundary loss\n",
    "\n",
    "    end = time.time()\n",
    "    input_ori, input, edge, mask = next(iter(dataLoader_train))\n",
    "    i = 0\n",
    "    for i, (input_ori, input, edge, mask) in enumerate(dataLoader_train):\n",
    "        data_time.update(time.time() - end)\n",
    "        input_ori_var = Variable(input_ori.cuda())\n",
    "        input_var = Variable(input.cuda())\n",
    "        edge_var = Variable(edge.cuda())\n",
    "        mask_var = Variable(mask.cuda())\n",
    "\n",
    "        if exp_args.addEdge == True:  # False\n",
    "            output_mask, output_edge = netmodel(input_var)\n",
    "            loss_mask = loss_Softmax(output_mask, mask_var)\n",
    "            losses_mask.update(loss_mask.item(), input.size(0))\n",
    "\n",
    "            # loss_edge = loss_l2(output_edge, edge_var) * exp_args.edgeRatio\n",
    "            loss_edge = loss_Focalloss(\n",
    "                output_edge, edge_var) * exp_args.edgeRatio\n",
    "            losses_edge.update(loss_edge.item(), input.size(0))\n",
    "\n",
    "            # total loss\n",
    "            loss = loss_mask + loss_edge\n",
    "\n",
    "            if exp_args.stability == True:  # False\n",
    "                output_mask_ori, output_edge_ori = netmodel(input_ori_var)\n",
    "                loss_mask_ori = loss_Softmax(output_mask_ori, mask_var)\n",
    "                losses_mask_ori.update(loss_mask_ori.item(), input.size(0))\n",
    "\n",
    "                # loss_edge_ori = loss_l2(output_edge_ori, edge_var) * exp_args.edgeRatio\n",
    "                loss_edge_ori = loss_Focalloss(\n",
    "                    output_edge_ori, edge_var) * exp_args.edgeRatio\n",
    "                losses_edge_ori.update(loss_edge_ori.item(), input.size(0))\n",
    "\n",
    "                # in our experiments, kl loss is better than l2 loss\n",
    "                if exp_args.use_kl == False:\n",
    "                    # consistency constraint loss: L2 distance\n",
    "                    loss_stability_mask = loss_l2(output_mask,\n",
    "                                                  Variable(output_mask_ori.data,\n",
    "                                                           requires_grad=False)) * exp_args.alpha\n",
    "                    loss_stability_edge = loss_l2(output_edge,\n",
    "                                                  Variable(output_edge_ori.data,\n",
    "                                                           requires_grad=False)) * exp_args.alpha * exp_args.edgeRatio\n",
    "                else:\n",
    "                    # consistency constraint loss: KL distance (better than L2 distance)\n",
    "                    loss_stability_mask = loss_KL(output_mask,\n",
    "                                                  Variable(\n",
    "                                                      output_mask_ori.data, requires_grad=False),\n",
    "                                                  exp_args.temperature) * exp_args.alpha\n",
    "                    loss_stability_edge = loss_KL(output_edge,\n",
    "                                                  Variable(\n",
    "                                                      output_edge_ori.data, requires_grad=False),\n",
    "                                                  exp_args.temperature) * exp_args.alpha * exp_args.edgeRatio\n",
    "\n",
    "                losses_stability_mask.update(\n",
    "                    loss_stability_mask.item(), input.size(0))\n",
    "                losses_stability_edge.update(\n",
    "                    loss_stability_edge.item(), input.size(0))\n",
    "\n",
    "                # total loss\n",
    "                # loss = loss_mask + loss_mask_ori + loss_edge + loss_edge_ori + loss_stability_mask + loss_stability_edge\n",
    "                loss = loss_mask + loss_mask_ori + loss_stability_mask + loss_edge\n",
    "        else:\n",
    "            output_mask = netmodel(input_var)\n",
    "            loss_mask = loss_Softmax(output_mask, mask_var)\n",
    "            losses_mask.update(loss_mask.item(), input.size(0))\n",
    "            # total loss: only include mask loss\n",
    "            loss = loss_mask\n",
    "\n",
    "            if exp_args.stability == True:\n",
    "                output_mask_ori = netmodel(input_ori_var)\n",
    "                loss_mask_ori = loss_Softmax(output_mask_ori, mask_var)\n",
    "                losses_mask_ori.update(loss_mask_ori.item(), input.size(0))\n",
    "                if exp_args.use_kl == False:\n",
    "                    # consistency constraint loss: L2 distance\n",
    "                    loss_stability_mask = loss_l2(output_mask,\n",
    "                                                  Variable(output_mask_ori.data,\n",
    "                                                           requires_grad=False)) * exp_args.alpha\n",
    "                else:\n",
    "                    # consistency constraint loss: KL distance (better than L2 distance)\n",
    "                    loss_stability_mask = loss_KL(output_mask,\n",
    "                                                  Variable(\n",
    "                                                      output_mask_ori.data, requires_grad=False),\n",
    "                                                  exp_args.temperature) * exp_args.alpha\n",
    "                losses_stability_mask.update(\n",
    "                    loss_stability_mask.item(), input.size(0))\n",
    "\n",
    "                # total loss\n",
    "                loss = loss_mask + loss_mask_ori + loss_stability_mask\n",
    "\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do Adam step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.printfreq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Lr-deconv: [{3}]\\t'\n",
    "                  'Lr-other: [{4}]\\t'\n",
    "                  # 'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  # 'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'.format(\n",
    "                      epoch, i, len(dataLoader_train),\n",
    "                      optimizer.param_groups[0]['lr'],\n",
    "                      optimizer.param_groups[1]['lr'],\n",
    "                      loss=losses))\n",
    "\n",
    "        ## '===========> logger <==========='\n",
    "        # (1) Log the scalar values\n",
    "        if exp_args.addEdge == True and exp_args.stability == True:\n",
    "            info = {  # batch_time.name: batch_time.val,\n",
    "                # data_time.name: data_time.val,\n",
    "                losses.name: losses.val,\n",
    "                losses_mask_ori.name: losses_mask_ori.val,\n",
    "                losses_mask.name: losses_mask.val,\n",
    "                losses_edge_ori.name: losses_edge_ori.val,\n",
    "                losses_edge.name: losses_edge.val,\n",
    "                losses_stability_mask.name: losses_stability_mask.val,\n",
    "                losses_stability_edge.name: losses_stability_edge.val\n",
    "            }\n",
    "        elif exp_args.addEdge == True and exp_args.stability == False:\n",
    "            info = {  # batch_time.name: batch_time.val,\n",
    "                # data_time.name: data_time.val,\n",
    "                losses.name: losses.val,\n",
    "                losses_mask.name: losses_mask.val,\n",
    "                losses_edge.name: losses_edge.val,\n",
    "            }\n",
    "        elif exp_args.addEdge == False and exp_args.stability == True:\n",
    "            info = {  # batch_time.name: batch_time.val,\n",
    "                # data_time.name: data_time.val,\n",
    "                losses.name: losses.val,\n",
    "                losses_mask_ori.name: losses_mask_ori.val,\n",
    "                losses_mask.name: losses_mask.val,\n",
    "                losses_stability_mask.name: losses_stability_mask.val,\n",
    "            }\n",
    "        elif exp_args.addEdge == False and exp_args.stability == False:\n",
    "            info = {  # batch_time.name: batch_time.val,\n",
    "                # data_time.name: data_time.val,\n",
    "                losses.name: losses.val,\n",
    "                losses_mask.name: losses_mask.val,\n",
    "            }\n",
    "        for tag, value in info.items():\n",
    "            logger.scalar_summary(tag, value, step=i)\n",
    "\n",
    "        '''\n",
    "        # (2) Log values and gradients of the parameters (histogram)\n",
    "        for tag, value in netmodel.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            logger.histo_summary(tag, value.data.cpu().numpy(), step=i)\n",
    "            if value.grad is None:\n",
    "                continue\n",
    "            logger.histo_summary(tag+'/grad', value.grad.cpu().data.numpy(), step=i)\n",
    "            break\n",
    "        '''\n",
    "\n",
    "        # (3) Log the images\n",
    "        if i % (args.printfreq) == 0:\n",
    "            num = 2\n",
    "            input_img = np.uint8((\n",
    "                Anti_Normalize_Img(\n",
    "                    np.transpose(input.cpu().numpy()[0:num], (0, 2, 3, 1)),\n",
    "                    scale=exp_args.img_scale,\n",
    "                    mean=exp_args.img_mean,\n",
    "                    val=exp_args.img_val)))[:, :, :, :3][:, :, :, ::-1]\n",
    "\n",
    "            if exp_args.video == True:\n",
    "                input_prior = np.float32(np.transpose(\n",
    "                    input.cpu().numpy()[0:num], (0, 2, 3, 1))[:, :, :, 3])\n",
    "\n",
    "            input_mask = mask.cpu().numpy()[0:num]\n",
    "            input_mask[input_mask == 255] = 0\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            prob = softmax(output_mask)\n",
    "            masks_pred = np.transpose(prob.data.cpu().numpy()[\n",
    "                                      0:num], (0, 2, 3, 1))[:, :, :, 1]\n",
    "\n",
    "            info = {}\n",
    "            info['input_img'] = input_img\n",
    "            if exp_args.video == True:\n",
    "                info['input_prior'] = input_prior*255\n",
    "            info['input_mask'] = input_mask*255\n",
    "            info['output_mask'] = masks_pred*255\n",
    "\n",
    "            if exp_args.addEdge == True:\n",
    "                input_edge = edge.cpu().numpy()[0:num]\n",
    "                edge_pred = np.transpose(output_edge.data.cpu().numpy()[\n",
    "                                         0:num], (0, 2, 3, 1))[:, :, :, 0]\n",
    "\n",
    "                if exp_args.stability == True:\n",
    "                    input_img_ori = np.uint8((\n",
    "                        Anti_Normalize_Img(\n",
    "                            np.transpose(input_ori.cpu().numpy()\n",
    "                                         [0:num], (0, 2, 3, 1)),\n",
    "                            scale=exp_args.img_scale,\n",
    "                            mean=exp_args.img_mean,\n",
    "                            val=exp_args.img_val)))[:, :, :, :3][:, :, :, ::-1]\n",
    "\n",
    "                    prob_ori = softmax(output_mask_ori)\n",
    "                    masks_pred_ori = np.transpose(prob_ori.data.cpu().numpy()[\n",
    "                                                  0:num], (0, 2, 3, 1))[:, :, :, 1]\n",
    "                    edge_pred_ori = np.transpose(output_edge_ori.data.cpu().numpy()[\n",
    "                                                 0:num], (0, 2, 3, 1))[:, :, :, 0]\n",
    "\n",
    "                    info['input_img_ori'] = input_img_ori\n",
    "                    info['output_mask_ori'] = masks_pred_ori*255\n",
    "\n",
    "                    info['input_edge'] = input_edge*255\n",
    "                    info['output_edge'] = edge_pred*255\n",
    "                    info['output_edge_ori'] = edge_pred_ori*255\n",
    "                else:\n",
    "                    info['input_edge'] = input_edge*255\n",
    "                    info['output_edge'] = edge_pred*255\n",
    "            else:\n",
    "                if exp_args.stability == True:\n",
    "                    input_img_ori = np.uint8((\n",
    "                        Anti_Normalize_Img(\n",
    "                            np.transpose(input_ori.cpu().numpy()\n",
    "                                         [0:num], (0, 2, 3, 1)),\n",
    "                            scale=exp_args.img_scale,\n",
    "                            mean=exp_args.img_mean,\n",
    "                            val=exp_args.img_val)))[:, :, :, :3][:, :, :, ::-1]\n",
    "\n",
    "                    prob_ori = softmax(output_mask_ori)\n",
    "                    masks_pred_ori = np.transpose(prob_ori.data.cpu().numpy()[\n",
    "                                                  0:num], (0, 2, 3, 1))[:, :, :, 1]\n",
    "\n",
    "                    info['input_img_ori'] = input_img_ori\n",
    "                    info['output_mask_ori'] = masks_pred_ori*255\n",
    "\n",
    "            print(np.max(masks_pred), np.min(masks_pred))\n",
    "\n",
    "            for tag, images in info.items():\n",
    "                logger.image_summary(tag, images, step=i)\n",
    "    pass\n",
    "\n",
    "def save_checkpoint(state, is_best, root, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, root+filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(root+filename, root+'model_best.pth.tar')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5d388fa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-12-02T07:04:22.093119Z",
     "iopub.status.busy": "2022-12-02T07:04:22.092852Z",
     "iopub.status.idle": "2022-12-02T07:13:22.353690Z",
     "shell.execute_reply": "2022-12-02T07:13:22.352403Z"
    },
    "papermill": {
     "duration": 540.282308,
     "end_time": "2022-12-02T07:13:22.356517",
     "exception": false,
     "start_time": "2022-12-02T07:04:22.074209",
     "status": "completed"
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-10-09T13:00:52.298259Z",
     "start_time": "2024-10-09T12:42:24.585922Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========>   training    <===========\n",
      "Epoch: [0][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 4.6353 (4.6353)\t\n",
      "1.0 0.38745472\n",
      "===========>   testing    <===========\n",
      "Epoch: [0][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7208 (0.7208)\t\n",
      "0.9983386 0.06352635\n",
      "Epoch: [0][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7643 (0.7317)\t\n",
      "0.997827 0.046776205\n",
      "Epoch: [0][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7281 (0.7301)\t\n",
      "0.9982083 0.034163494\n",
      "loss:  0.6100279823962027 10000\n",
      "===========>   training    <===========\n",
      "Epoch: [1][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7705 (0.7705)\t\n",
      "0.99999976 0.00028525456\n",
      "===========>   testing    <===========\n",
      "Epoch: [1][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7147 (0.7147)\t\n",
      "0.99180496 0.05894638\n",
      "Epoch: [1][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7442 (0.7518)\t\n",
      "0.9997707 0.0032961331\n",
      "Epoch: [1][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7253 (0.7377)\t\n",
      "0.9951466 0.012856162\n",
      "loss:  0.6463287509695028 0.6100279823962027\n",
      "===========>   training    <===========\n",
      "Epoch: [2][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7080 (0.7080)\t\n",
      "0.99776196 0.05777515\n",
      "===========>   testing    <===========\n",
      "Epoch: [2][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6984 (0.6984)\t\n",
      "0.9268754 0.11197629\n",
      "Epoch: [2][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7327 (0.7265)\t\n",
      "0.99998784 2.621631e-07\n",
      "Epoch: [2][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7056 (0.7158)\t\n",
      "0.9869745 0.042661604\n",
      "loss:  0.6722701551964418 0.6100279823962027\n",
      "===========>   training    <===========\n",
      "Epoch: [3][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6982 (0.6982)\t\n",
      "1.0 8.207344e-24\n",
      "===========>   testing    <===========\n",
      "Epoch: [3][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6839 (0.6839)\t\n",
      "0.85365534 0.25563854\n",
      "Epoch: [3][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.7112 (0.6977)\t\n",
      "0.9991872 4.084757e-05\n",
      "Epoch: [3][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6957 (0.6939)\t\n",
      "0.9699887 0.11747577\n",
      "loss:  0.6061574114809702 0.6100279823962027\n",
      "===========>   training    <===========\n",
      "Epoch: [4][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6867 (0.6867)\t\n",
      "0.98745584 0.004231308\n",
      "===========>   testing    <===========\n",
      "Epoch: [4][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6454 (0.6454)\t\n",
      "0.8114618 0.22176576\n",
      "Epoch: [4][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6445 (0.6556)\t\n",
      "0.9950165 0.0027745662\n",
      "Epoch: [4][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6677 (0.6527)\t\n",
      "0.9392599 0.11132144\n",
      "loss:  0.5651563378634152 0.6061574114809702\n",
      "===========>   training    <===========\n",
      "Epoch: [5][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6601 (0.6601)\t\n",
      "0.868218 0.22636446\n",
      "===========>   testing    <===========\n",
      "Epoch: [5][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5511 (0.5511)\t\n",
      "0.9064588 0.0599921\n",
      "Epoch: [5][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6205 (0.5312)\t\n",
      "0.9995159 6.563172e-05\n",
      "Epoch: [5][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6021 (0.5300)\t\n",
      "0.9527244 0.0648876\n",
      "loss:  0.44176088549208237 0.5651563378634152\n",
      "===========>   training    <===========\n",
      "Epoch: [6][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5605 (0.5605)\t\n",
      "0.9437867 0.040129565\n",
      "===========>   testing    <===========\n",
      "Epoch: [6][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5100 (0.5100)\t\n",
      "0.9815718 0.015933225\n",
      "Epoch: [6][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5739 (0.4976)\t\n",
      "0.9998677 8.604443e-06\n",
      "Epoch: [6][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.6217 (0.4912)\t\n",
      "0.97767794 0.016225347\n",
      "loss:  0.48484341164188227 0.44176088549208237\n",
      "===========>   training    <===========\n",
      "Epoch: [7][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4870 (0.4870)\t\n",
      "0.96586263 0.012516482\n",
      "===========>   testing    <===========\n",
      "Epoch: [7][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4051 (0.4051)\t\n",
      "0.96600056 0.007842439\n",
      "Epoch: [7][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5186 (0.4209)\t\n",
      "0.9975533 0.0063282354\n",
      "Epoch: [7][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5376 (0.4270)\t\n",
      "0.97114503 0.0073552965\n",
      "loss:  0.39484684039271434 0.44176088549208237\n",
      "===========>   training    <===========\n",
      "Epoch: [8][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4549 (0.4549)\t\n",
      "0.9582856 0.0087159285\n",
      "===========>   testing    <===========\n",
      "Epoch: [8][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3629 (0.3629)\t\n",
      "0.94461054 0.0045383866\n",
      "Epoch: [8][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5198 (0.3985)\t\n",
      "0.99696404 0.0044534\n",
      "Epoch: [8][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4688 (0.4051)\t\n",
      "0.94842196 0.0048650713\n",
      "loss:  0.3524734606877844 0.39484684039271434\n",
      "===========>   training    <===========\n",
      "Epoch: [9][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4546 (0.4546)\t\n",
      "0.974162 0.0067754765\n",
      "===========>   testing    <===========\n",
      "Epoch: [9][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3813 (0.3813)\t\n",
      "0.96141714 0.0010664251\n",
      "Epoch: [9][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5506 (0.3904)\t\n",
      "0.9975789 0.0010886907\n",
      "Epoch: [9][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4560 (0.3969)\t\n",
      "0.9569874 0.0012691185\n",
      "loss:  0.33986593252170005 0.3524734606877844\n",
      "===========>   training    <===========\n",
      "Epoch: [10][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3928 (0.3928)\t\n",
      "0.9993931 0.002394332\n",
      "===========>   testing    <===========\n",
      "Epoch: [10][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3689 (0.3689)\t\n",
      "0.967108 0.000880303\n",
      "Epoch: [10][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5863 (0.3713)\t\n",
      "0.99827266 0.0010862412\n",
      "Epoch: [10][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4247 (0.3723)\t\n",
      "0.9622925 0.0011502852\n",
      "loss:  0.30652560411139007 0.33986593252170005\n",
      "===========>   training    <===========\n",
      "Epoch: [11][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4258 (0.4258)\t\n",
      "0.9663763 0.007311373\n",
      "===========>   testing    <===========\n",
      "Epoch: [11][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.2829 (0.2829)\t\n",
      "0.9741455 0.00066448684\n",
      "Epoch: [11][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4135 (0.3639)\t\n",
      "0.99065125 0.0005781485\n",
      "Epoch: [11][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3938 (0.3700)\t\n",
      "0.9717747 0.0006688693\n",
      "loss:  0.2881945810473685 0.30652560411139007\n",
      "===========>   training    <===========\n",
      "Epoch: [12][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4038 (0.4038)\t\n",
      "0.9730866 0.0004185516\n",
      "===========>   testing    <===========\n",
      "Epoch: [12][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3296 (0.3296)\t\n",
      "0.97869086 0.0006246549\n",
      "Epoch: [12][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4020 (0.3223)\t\n",
      "0.98953503 0.0006742628\n",
      "Epoch: [12][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4033 (0.3297)\t\n",
      "0.97379917 0.0006183494\n",
      "loss:  0.25696128268660157 0.2881945810473685\n",
      "===========>   training    <===========\n",
      "Epoch: [13][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3747 (0.3747)\t\n",
      "0.9913504 0.0020470219\n",
      "===========>   testing    <===========\n",
      "Epoch: [13][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4205 (0.4205)\t\n",
      "0.97733706 0.0006379812\n",
      "Epoch: [13][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4500 (0.3311)\t\n",
      "0.94721466 0.0007630428\n",
      "Epoch: [13][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4470 (0.3354)\t\n",
      "0.976118 0.0006049696\n",
      "loss:  0.2771637879847729 0.25696128268660157\n",
      "===========>   training    <===========\n",
      "Epoch: [14][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3135 (0.3135)\t\n",
      "0.975178 0.0013071329\n",
      "===========>   testing    <===========\n",
      "Epoch: [14][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3944 (0.3944)\t\n",
      "0.9821675 0.0009573213\n",
      "Epoch: [14][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4911 (0.3349)\t\n",
      "0.9574819 0.0010653428\n",
      "Epoch: [14][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4089 (0.3450)\t\n",
      "0.9810354 0.00075497595\n",
      "loss:  0.2679997566893554 0.25696128268660157\n",
      "===========>   training    <===========\n",
      "Epoch: [15][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3391 (0.3391)\t\n",
      "0.98183435 0.0015568696\n",
      "===========>   testing    <===========\n",
      "Epoch: [15][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3221 (0.3221)\t\n",
      "0.9830873 0.0009343125\n",
      "Epoch: [15][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4510 (0.3161)\t\n",
      "0.96163386 0.000919365\n",
      "Epoch: [15][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3996 (0.3284)\t\n",
      "0.9825882 0.00076897343\n",
      "loss:  0.2539399541658548 0.25696128268660157\n",
      "===========>   training    <===========\n",
      "Epoch: [16][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3328 (0.3328)\t\n",
      "0.99932384 0.0038577646\n",
      "===========>   testing    <===========\n",
      "Epoch: [16][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3128 (0.3128)\t\n",
      "0.984159 0.00055421254\n",
      "Epoch: [16][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4163 (0.3145)\t\n",
      "0.9664142 0.0007456278\n",
      "Epoch: [16][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3684 (0.3236)\t\n",
      "0.98213357 0.00068375573\n",
      "loss:  0.2507762247363403 0.2539399541658548\n",
      "===========>   training    <===========\n",
      "Epoch: [17][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3030 (0.3030)\t\n",
      "0.98445815 0.00045799388\n",
      "===========>   testing    <===========\n",
      "Epoch: [17][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4203 (0.4203)\t\n",
      "0.98414534 0.00027974253\n",
      "Epoch: [17][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3930 (0.3182)\t\n",
      "0.95043266 0.00032109628\n",
      "Epoch: [17][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3668 (0.3189)\t\n",
      "0.9828395 0.00028334014\n",
      "loss:  0.2595135231987411 0.2507762247363403\n",
      "===========>   training    <===========\n",
      "Epoch: [18][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3151 (0.3151)\t\n",
      "0.99999845 0.00067881285\n",
      "===========>   testing    <===========\n",
      "Epoch: [18][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3201 (0.3201)\t\n",
      "0.9858133 0.0009063291\n",
      "Epoch: [18][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.4880 (0.3077)\t\n",
      "0.96503407 0.0010685174\n",
      "Epoch: [18][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3312 (0.3133)\t\n",
      "0.9840455 0.0009493582\n",
      "loss:  0.24020584413019674 0.2507762247363403\n",
      "===========>   training    <===========\n",
      "Epoch: [19][0/23]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3185 (0.3185)\t\n",
      "0.9955544 0.0030424134\n",
      "===========>   testing    <===========\n",
      "Epoch: [19][0/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3251 (0.3251)\t\n",
      "0.9844103 0.00040390601\n",
      "Epoch: [19][100/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.5045 (0.2928)\t\n",
      "0.9616858 0.0005614651\n",
      "Epoch: [19][200/289]\tLr-deconv: [0.0]\tLr-other: [0.001]\tLoss 0.3557 (0.3027)\t\n",
      "0.9833703 0.0006762642\n",
      "loss:  0.2314790919225671 0.24020584413019674\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for epoch in range(gap, 20):\n",
    "    adjust_learning_rate(optimizer, epoch, args, multiple)\n",
    "    print('===========>   training    <===========')\n",
    "    train(dataLoader_train, netmodel, optimizer, epoch, logger_train, exp_args)\n",
    "    print('===========>   testing    <===========')\n",
    "    loss = test(dataLoader_test, netmodel, optimizer,epoch, logger_test, exp_args)\n",
    "    print(\"loss: \", loss, minLoss)\n",
    "    is_best = False\n",
    "    if loss < minLoss:\n",
    "        minLoss = loss\n",
    "        is_best = True\n",
    "\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch+1,\n",
    "        'minLoss': minLoss,\n",
    "        'state_dict': netmodel.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, exp_args.model_root)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 647.145462,
   "end_time": "2022-12-02T07:13:26.281850",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-12-02T07:02:39.136388",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
